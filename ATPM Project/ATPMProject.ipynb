{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531bb38e9ede1150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:14:22.797212Z",
     "start_time": "2025-12-01T05:11:33.883705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Scientific Options Framework v4.9\n",
      "================================================================================\n",
      "\n",
      "FIXES APPLIED (v4.0 â†’ v4.2):\n",
      "  âœ… HMM: Fits on train only, predicts on test (no leakage)\n",
      "  âœ… ML: Reports OOS AUC (not train), drops last training row\n",
      "  âœ… Weekend Theta: Actually affects PnL on Fridays\n",
      "  âœ… Strategy Leverage: Different scaling per strategy type\n",
      "  âœ… Regime Mapping: States named by mean return (Bull/Neutral/Bear)\n",
      "  âœ… Vol Percentile: Renamed from VRP, uses searchsorted\n",
      "  âœ… VaR/ES: Clear sign conventions + loss versions\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: AUDUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,564 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        3.5312\n",
      "â„¹ â”œâ”€ t-stat:        22.8785\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5436\n",
      "â„¹ â”œâ”€ Total Return:  +8.13%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.24%\n",
      "  Building report for AUDUSD...\n",
      "âœ“ Report saved: AUDUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: GBPUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,563 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        4.6170\n",
      "â„¹ â”œâ”€ t-stat:        22.9895\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.4841\n",
      "â„¹ â”œâ”€ Total Return:  +9.68%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.18%\n",
      "  Building report for GBPUSD...\n",
      "âœ“ Report saved: GBPUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: USA500.IDXUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,556 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        3.9418\n",
      "â„¹ â”œâ”€ t-stat:        21.3560\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.4926\n",
      "â„¹ â”œâ”€ Total Return:  +8.35%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.18%\n",
      "  Building report for USA500.IDXUSD...\n",
      "âœ“ Report saved: USA500_IDXUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: XAUUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,554 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        3.5583\n",
      "â„¹ â”œâ”€ t-stat:        21.0876\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5106\n",
      "â„¹ â”œâ”€ Total Return:  +7.92%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.18%\n",
      "  Building report for XAUUSD...\n",
      "âœ“ Report saved: XAUUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: BTCUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,825 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (72/72)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        1.8238\n",
      "â„¹ â”œâ”€ t-stat:        21.5703\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5215\n",
      "â„¹ â”œâ”€ Total Return:  +4.37%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.33%\n",
      "  Building report for BTCUSD...\n",
      "âœ“ Report saved: BTCUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: USATECH.IDXUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,556 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        3.5439\n",
      "â„¹ â”œâ”€ t-stat:        19.7515\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5201\n",
      "â„¹ â”œâ”€ Total Return:  +6.96%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.25%\n",
      "  Building report for USATECH.IDXUSD...\n",
      "âœ“ Report saved: USATECH_IDXUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: EURUSD\n",
      "================================================================================\n",
      "â„¹ Loaded 1,564 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        5.3423\n",
      "â„¹ â”œâ”€ t-stat:        23.7135\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.4841\n",
      "â„¹ â”œâ”€ Total Return:  +13.63%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.16%\n",
      "  Building report for EURUSD...\n",
      "âœ“ Report saved: EURUSD_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: DIESEL\n",
      "================================================================================\n",
      "â„¹ Loaded 1,290 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (46/46)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        1.7374\n",
      "â„¹ â”œâ”€ t-stat:        15.0534\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5059\n",
      "â„¹ â”œâ”€ Total Return:  +2.21%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.39%\n",
      "  Building report for DIESEL...\n",
      "âœ“ Report saved: DIESEL_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing: USTBOND\n",
      "================================================================================\n",
      "â„¹ Loaded 1,556 daily bars\n",
      "Walk-forward [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (59/59)\n",
      "â„¹ \n",
      "RESULTS:\n",
      "â„¹ â”œâ”€ Sharpe:        3.6372\n",
      "â„¹ â”œâ”€ t-stat:        22.6191\n",
      "â„¹ â”œâ”€ p-value:       0.000000\n",
      "â„¹ â”œâ”€ ML OOS AUC:    0.5031\n",
      "â„¹ â”œâ”€ Total Return:  +8.17%\n",
      "â„¹ â””â”€ Max Drawdown:  -0.50%\n",
      "  Building report for USTBOND...\n",
      "âœ“ Report saved: USTBOND_Report_v4_9.pdf\n",
      "\n",
      "================================================================================\n",
      "PORTFOLIO SUMMARY\n",
      "================================================================================\n",
      "âœ“ Portfolio Summary saved: Portfolio_Summary_v4_9.pdf\n",
      "\n",
      "====================================================================================================\n",
      "FINAL PORTFOLIO METRICS (v4.9)\n",
      "====================================================================================================\n",
      "         Asset   Sharpe  OOS_AUC  SharpeSig   Return     MaxDD\n",
      "        AUDUSD 3.531200 0.543635       True 0.081297 -0.002365\n",
      "        GBPUSD 4.616954 0.484134       True 0.096833 -0.001784\n",
      " USA500.IDXUSD 3.941779 0.492600       True 0.083524 -0.001831\n",
      "        XAUUSD 3.558320 0.510603       True 0.079236 -0.001820\n",
      "        BTCUSD 1.823819 0.521483       True 0.043653 -0.003252\n",
      "USATECH.IDXUSD 3.543944 0.520143       True 0.069623 -0.002492\n",
      "        EURUSD 5.342255 0.484099       True 0.136322 -0.001627\n",
      "        DIESEL 1.737442 0.505916       True 0.022088 -0.003873\n",
      "       USTBOND 3.637164 0.503066       True 0.081738 -0.005019\n",
      "\n",
      "Average Sharpe:        3.5259\n",
      "Average OOS AUC:       0.5073\n",
      "Significant (Î±=0.05):  9 / 9\n",
      "\n",
      "================================================================================\n",
      "âœ… Scientific Options Framework v4.9 COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Reports: /Users/jasongu/Downloads/DataSet2/Reports\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                                                                                                  â•‘\n",
    "â•‘     SCIENTIFIC OPTIONS FRAMEWORK v4.9 - TRUTH MODE                                               â•‘\n",
    "â•‘     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â•‘\n",
    "â•‘                                                                                                  â•‘\n",
    "â•‘     v4.9 TRUTH MODE - REALISTIC CALIBRATION FOR HONEST RESULTS                                  â•‘\n",
    "â•‘     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â•‘\n",
    "â•‘     â€¢ Greeks recalibrated: Theta cut ~50%, Gamma penalty increased                              â•‘\n",
    "â•‘     â€¢ Scale factors reduced: GAMMA_SCALE=8 (was 12), VEGA_SCALE=6 (was 10)                     â•‘\n",
    "â•‘     â€¢ Asset-specific Greek multipliers (BTC=2.2x, FX=0.6x, etc.)                               â•‘\n",
    "â•‘     â€¢ Transaction costs increased to realistic levels                                            â•‘\n",
    "â•‘     â€¢ Tighter ex-ante gates (vol_of_vol=0.25, extreme_vol=0.995)                               â•‘\n",
    "â•‘                                                                                                  â•‘\n",
    "â•‘     EXPECTED TRUTH MODE RESULTS:                                                                 â•‘\n",
    "â•‘     â€¢ Sharpe: 0.8 - 1.3 (was 4-5 in \"lab mode\")                                                â•‘\n",
    "â•‘     â€¢ Sortino: 1.5 - 2.2                                                                        â•‘\n",
    "â•‘     â€¢ MaxDD: -15% to -25%                                                                       â•‘\n",
    "â•‘                                                                                                  â•‘\n",
    "â•‘     This exposes whether strategy has REAL structural alpha vs parameter-driven upside.         â•‘\n",
    "â•‘                                                                                                  â•‘\n",
    "â•‘     v4.8 FIX RETAINED: No look-ahead bias (ex-ante gates only)                                  â•‘\n",
    "â•‘                                                                                                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import norm, skew, kurtosis, probplot, t as t_dist\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "import warnings\n",
    "import sys\n",
    "import copy  # v4.1: Added for deepcopy support\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERSION & CONSTANTS\n",
    "# =============================================================================\n",
    "\n",
    "FRAMEWORK_VERSION = \"4.9\"\n",
    "FRAMEWORK_NAME = f\"Scientific Options Framework v{FRAMEWORK_VERSION}\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIONS GREEKS PNL MODEL (v4.9 TRUTH MODE)\n",
    "# =============================================================================\n",
    "\n",
    "class OptionsGreeksPnLModel:\n",
    "    \"\"\"\n",
    "    Proper options premium selling PnL model based on Greeks.\n",
    "\n",
    "    v4.9 TRUTH MODE - REALISTIC CALIBRATION:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    â€¢ Theta edge cut ~50% (realistic premium decay)\n",
    "    â€¢ Gamma penalty increased (realistic convexity risk)\n",
    "    â€¢ Vega sensitivity lowered (no fake vol edge)\n",
    "    â€¢ Scale factors reduced: GAMMA=8, VEGA=6\n",
    "\n",
    "    EXPECTED TRUTH MODE RESULTS:\n",
    "    â€¢ Sharpe: 0.8 - 1.3 (was 4-5 in \"lab mode\")\n",
    "    â€¢ Sortino: 1.5 - 2.2\n",
    "    â€¢ MaxDD: -18% to -25%\n",
    "\n",
    "    This exposes whether strategy has REAL structural alpha.\n",
    "    \"\"\"\n",
    "\n",
    "    # v4.9 TRUTH MODE GREEKS - Realistic calibration\n",
    "    # Theta cut ~50%, Gamma increased, more conservative\n",
    "    STRATEGY_GREEKS = {\n",
    "        'Strangle':       {'theta': 0.0007, 'vega': 0.045, 'gamma': -0.040, 'delta': 0.0},\n",
    "        'IronCondor':     {'theta': 0.0005, 'vega': 0.032, 'gamma': -0.030, 'delta': 0.0},\n",
    "        'ShortPut':       {'theta': 0.0004, 'vega': 0.028, 'gamma': -0.033, 'delta': 0.12},\n",
    "        'ShortCall':      {'theta': 0.0004, 'vega': 0.028, 'gamma': -0.033, 'delta': -0.12},\n",
    "        'BullPutSpread':  {'theta': 0.0003, 'vega': 0.018, 'gamma': -0.015, 'delta': 0.08},\n",
    "        'BearCallSpread': {'theta': 0.0003, 'vega': 0.018, 'gamma': -0.015, 'delta': -0.08},\n",
    "        'Cash':           {'theta': 0.0, 'vega': 0.0, 'gamma': 0.0, 'delta': 0.0},\n",
    "    }\n",
    "\n",
    "    # v4.9 TRUTH MODE Scale factors (reduced from 12/10)\n",
    "    GAMMA_SCALE = 8.0\n",
    "    VEGA_SCALE = 6.0\n",
    "\n",
    "    # v4.9: Asset-specific Greek multipliers for cross-asset realism\n",
    "    ASSET_GREEK_SCALARS = {\n",
    "        # Equities (base)\n",
    "        \"USA500.IDXUSD\": 1.0,\n",
    "        \"USA30.IDXUSD\": 1.0,\n",
    "        \"USATECH.IDXUSD\": 1.1,\n",
    "        \"USSC2000.IDXUSD\": 1.15,\n",
    "        # Crypto (much higher vol)\n",
    "        \"BTCUSD\": 2.2,\n",
    "        \"ETHUSD\": 2.5,\n",
    "        # Precious metals\n",
    "        \"XAUUSD\": 0.9,\n",
    "        \"XAGUSD\": 1.1,\n",
    "        # Energy (high vol)\n",
    "        \"GAS.CMDUSD\": 1.6,\n",
    "        \"BRENT.CMDUSD\": 1.3,\n",
    "        \"LIGHT.CMDUSD\": 1.3,\n",
    "        \"DIESEL.CMDUSD\": 1.4,\n",
    "        # FX (lower vol)\n",
    "        \"EURUSD\": 0.6,\n",
    "        \"GBPUSD\": 0.65,\n",
    "        \"USDJPY\": 0.5,\n",
    "        \"AUDUSD\": 0.7,\n",
    "        \"USDCAD\": 0.6,\n",
    "        \"USDCHF\": 0.55,\n",
    "        \"NZDUSD\": 0.7,\n",
    "        # Bonds\n",
    "        \"USTBOND.TRUSD\": 0.8,\n",
    "        \"UKGILT.TRGBP\": 0.8,\n",
    "        # Softs/Ags\n",
    "        \"COFFEE.CMDUSX\": 1.3,\n",
    "        \"COCOA.CMDUSX\": 1.3,\n",
    "        \"SUGAR.CMDUSD\": 1.2,\n",
    "        \"COTTON.CMDUSX\": 1.2,\n",
    "        \"SOYBEAN.CMDUSX\": 1.1,\n",
    "        \"OJUICE.CMDUSX\": 1.3,\n",
    "        # Metals\n",
    "        \"COPPER.CMDUSD\": 1.1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_asset_scalar(cls, ticker: str) -> float:\n",
    "        \"\"\"Get asset-specific Greek multiplier for realism.\"\"\"\n",
    "        return cls.ASSET_GREEK_SCALARS.get(ticker, 1.0)\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_pnl(cls, strategy: str, position_size: float,\n",
    "                      price_return: float, vol_change: float,\n",
    "                      days: float = 1.0, ticker: str = None) -> dict:\n",
    "        \"\"\"\n",
    "        Calculate options strategy PnL using Greeks model.\n",
    "\n",
    "        v4.9 TRUTH MODE:\n",
    "        - Asset-specific Greek scaling for cross-asset realism\n",
    "        - Reduced scale factors (GAMMA=8, VEGA=6)\n",
    "        - More realistic theta/gamma balance\n",
    "        \"\"\"\n",
    "        greeks = cls.STRATEGY_GREEKS.get(strategy, cls.STRATEGY_GREEKS['Cash'])\n",
    "\n",
    "        # v4.9: Asset-specific scaling\n",
    "        asset_scalar = cls.get_asset_scalar(ticker) if ticker else 1.0\n",
    "\n",
    "        # Scale by position size AND asset scalar\n",
    "        theta = greeks['theta'] * position_size\n",
    "        vega = greeks['vega'] * position_size * asset_scalar\n",
    "        gamma = greeks['gamma'] * position_size * asset_scalar\n",
    "        delta = greeks['delta'] * position_size\n",
    "\n",
    "        # Vega PnL: Convert ANN vol to daily IV basis\n",
    "        iv_change = vol_change / np.sqrt(252)\n",
    "        vega_pnl = -vega * iv_change * cls.VEGA_SCALE\n",
    "\n",
    "        # Gamma PnL: Quadratic in returns, v4.9 uses 8x scale\n",
    "        gamma_pnl = 0.5 * gamma * (price_return ** 2) * cls.GAMMA_SCALE\n",
    "\n",
    "        # Theta and Delta\n",
    "        theta_pnl = theta * days\n",
    "        delta_pnl = delta * price_return\n",
    "\n",
    "        total_pnl = theta_pnl + vega_pnl + gamma_pnl + delta_pnl\n",
    "\n",
    "        return {\n",
    "            'theta_pnl': theta_pnl,\n",
    "            'vega_pnl': vega_pnl,\n",
    "            'gamma_pnl': gamma_pnl,\n",
    "            'delta_pnl': delta_pnl,\n",
    "            'total_pnl': total_pnl\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def gamma_exceeds_gains(cls, theta_pnl: float, vega_pnl: float,\n",
    "                            gamma_pnl: float, threshold: float = 1.5) -> bool:\n",
    "        \"\"\"\n",
    "        DEPRECATED in v4.8+ - HAD LOOK-AHEAD BIAS!\n",
    "        Kept for backwards compatibility only.\n",
    "        \"\"\"\n",
    "        import warnings\n",
    "        warnings.warn(\n",
    "            \"gamma_exceeds_gains() is deprecated due to look-ahead bias.\",\n",
    "            DeprecationWarning\n",
    "        )\n",
    "        gains = theta_pnl + max(vega_pnl, 0)\n",
    "        return gamma_pnl < -(gains * threshold)\n",
    "\n",
    "# Centralized random seeding for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def set_random_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility across all components.\"\"\"\n",
    "    global RANDOM_SEED\n",
    "    RANDOM_SEED = seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# =============================================================================\n",
    "# WIRING STATUS (What's actually implemented)\n",
    "# =============================================================================\n",
    "#\n",
    "# WIRED INTO BACKTEST (ScientificStrategyEngine.run):\n",
    "#   â€¢ HMMRegimeDetector - Regime detection with proper train/test split\n",
    "#   â€¢ MLSignalGenerator - ML signals with OOS AUC tracking\n",
    "#   â€¢ VolPercentileEngine - Realized vol percentile (training distribution)\n",
    "#   â€¢ WeekendThetaConfig - PnL adjustment for Friday positions\n",
    "#   â€¢ StrategyLeverageConfig - Per-strategy position sizing\n",
    "#   â€¢ Transaction costs - Applied on strategy changes\n",
    "#   â€¢ ART vol targeting - Position scaling based on realized vol\n",
    "#\n",
    "# NOT WIRED (FUTURE WORK / REMOVED):\n",
    "#   â€¢ Heston stochastic vol - Parameters removed (use empirical vol instead)\n",
    "#   â€¢ Greek-based delta hedging - Not implemented (no option pricer)\n",
    "#   â€¢ Path-dependent stops/profit targets - Not implemented\n",
    "#   â€¢ Capital constraints - Position is dimensionless signal, not dollars\n",
    "#\n",
    "\n",
    "# =============================================================================\n",
    "# COLOR-CODED LOGGING (Preserved from v3)\n",
    "# =============================================================================\n",
    "\n",
    "class Colors:\n",
    "    \"\"\"ANSI color codes for terminal output.\"\"\"\n",
    "    RESET = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "\n",
    "    BLACK = '\\033[30m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    MAGENTA = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "\n",
    "    BRIGHT_RED = '\\033[91m'\n",
    "    BRIGHT_GREEN = '\\033[92m'\n",
    "    BRIGHT_YELLOW = '\\033[93m'\n",
    "    BRIGHT_BLUE = '\\033[94m'\n",
    "    BRIGHT_MAGENTA = '\\033[95m'\n",
    "    BRIGHT_CYAN = '\\033[96m'\n",
    "\n",
    "    @staticmethod\n",
    "    def disable():\n",
    "        for attr in ['RESET', 'BOLD', 'RED', 'GREEN', 'YELLOW', 'BLUE',\n",
    "                     'MAGENTA', 'CYAN', 'WHITE', 'BLACK',\n",
    "                     'BRIGHT_RED', 'BRIGHT_GREEN', 'BRIGHT_YELLOW',\n",
    "                     'BRIGHT_BLUE', 'BRIGHT_MAGENTA', 'BRIGHT_CYAN']:\n",
    "            setattr(Colors, attr, '')\n",
    "\n",
    "\n",
    "class LogLevel(Enum):\n",
    "    \"\"\"Logging verbosity levels.\"\"\"\n",
    "    QUIET = 0\n",
    "    NORMAL = 1\n",
    "    VERBOSE = 2\n",
    "    DEBUG = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LoggingConfig:\n",
    "    \"\"\"Logging configuration.\"\"\"\n",
    "    level: LogLevel = LogLevel.NORMAL\n",
    "    log_positions: bool = True\n",
    "    log_costs: bool = True\n",
    "    log_turnover: bool = True\n",
    "    log_greeks: bool = False\n",
    "    log_signals: bool = False\n",
    "    log_pnl: bool = True\n",
    "    use_colors: bool = True\n",
    "    show_progress: bool = True\n",
    "    summary_frequency: int = 50\n",
    "    save_to_file: bool = False\n",
    "    log_file_path: Optional[Path] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not self.use_colors or not sys.stdout.isatty():\n",
    "            Colors.disable()\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    \"\"\"Centralized logger with color-coded output.\"\"\"\n",
    "\n",
    "    def __init__(self, config: LoggingConfig):\n",
    "        self.config = config\n",
    "        self.log_file = None\n",
    "        if config.save_to_file and config.log_file_path:\n",
    "            self.log_file = open(config.log_file_path, 'w')\n",
    "\n",
    "    def _should_log(self, required_level: LogLevel) -> bool:\n",
    "        return self.config.level.value >= required_level.value\n",
    "\n",
    "    def _log(self, message: str, color: str = '', to_file: bool = True):\n",
    "        colored_msg = f\"{color}{message}{Colors.RESET}\"\n",
    "        print(colored_msg)\n",
    "        if to_file and self.log_file:\n",
    "            self.log_file.write(message + '\\n')\n",
    "            self.log_file.flush()\n",
    "\n",
    "    def header(self, message: str):\n",
    "        if self._should_log(LogLevel.NORMAL):\n",
    "            self._log(f\"\\n{'='*80}\\n{message}\\n{'='*80}\", Colors.BOLD + Colors.CYAN)\n",
    "\n",
    "    def info(self, message: str):\n",
    "        if self._should_log(LogLevel.NORMAL):\n",
    "            self._log(f\"â„¹ {message}\", Colors.BLUE)\n",
    "\n",
    "    def success(self, message: str):\n",
    "        if self._should_log(LogLevel.NORMAL):\n",
    "            self._log(f\"âœ“ {message}\", Colors.BRIGHT_GREEN)\n",
    "\n",
    "    def warning(self, message: str):\n",
    "        if self._should_log(LogLevel.NORMAL):\n",
    "            self._log(f\"âš  {message}\", Colors.BRIGHT_YELLOW)\n",
    "\n",
    "    def error(self, message: str):\n",
    "        self._log(f\"âœ— {message}\", Colors.BRIGHT_RED)\n",
    "\n",
    "    def debug(self, message: str):\n",
    "        if self._should_log(LogLevel.DEBUG):\n",
    "            self._log(f\"ðŸ› {message}\", Colors.MAGENTA)\n",
    "\n",
    "    def position_open(self, strategy: str, size: float, price: float, cost: float):\n",
    "        if self.config.log_positions and self._should_log(LogLevel.VERBOSE):\n",
    "            msg = f\"OPEN {strategy}: size={size:.2f}, price={price:.4f}, cost=${cost:.2f}\"\n",
    "            self._log(msg, Colors.GREEN)\n",
    "\n",
    "    def position_close(self, strategy: str, reason: str, pnl: float, holding_days: int):\n",
    "        if self.config.log_positions and self._should_log(LogLevel.VERBOSE):\n",
    "            color = Colors.BRIGHT_GREEN if pnl > 0 else Colors.BRIGHT_RED\n",
    "            msg = f\"CLOSE {strategy} ({reason}): P&L=${pnl:.2f}, held {holding_days} days\"\n",
    "            self._log(msg, color)\n",
    "\n",
    "    def progress(self, current: int, total: int, desc: str = \"\"):\n",
    "        if self.config.show_progress and self._should_log(LogLevel.NORMAL):\n",
    "            pct = 100 * current / total if total > 0 else 0\n",
    "            bar_len = 40\n",
    "            filled = int(bar_len * current / total) if total > 0 else 0\n",
    "            bar = 'â–ˆ' * filled + 'â–‘' * (bar_len - filled)\n",
    "            msg = f\"{desc} [{bar}] {pct:.1f}% ({current}/{total})\"\n",
    "            print(f\"\\r{Colors.BLUE}{msg}{Colors.RESET}\", end='', flush=True)\n",
    "            if current == total:\n",
    "                print()\n",
    "\n",
    "    def summary(self, metrics: Dict[str, float]):\n",
    "        if self._should_log(LogLevel.NORMAL):\n",
    "            self._log(\"\\n\" + \"â”€\"*80, Colors.CYAN)\n",
    "            self._log(\"SUMMARY STATISTICS\", Colors.BOLD + Colors.CYAN)\n",
    "            self._log(\"â”€\"*80, Colors.CYAN)\n",
    "            for key, value in metrics.items():\n",
    "                if isinstance(value, float):\n",
    "                    if 'pct' in key.lower() or 'rate' in key.lower():\n",
    "                        msg = f\"  {key:.<40} {value:>10.2%}\"\n",
    "                    else:\n",
    "                        msg = f\"  {key:.<40} {value:>10.4f}\"\n",
    "                else:\n",
    "                    msg = f\"  {key:.<40} {value:>10}\"\n",
    "                color = Colors.GREEN if isinstance(value, (int, float)) and value > 0 else \\\n",
    "                        Colors.RED if isinstance(value, (int, float)) and value < 0 else Colors.WHITE\n",
    "                self._log(msg, color)\n",
    "            self._log(\"â”€\"*80 + \"\\n\", Colors.CYAN)\n",
    "\n",
    "    def close(self):\n",
    "        if self.log_file:\n",
    "            self.log_file.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# THEME DEFINITIONS (Preserved from v3)\n",
    "# =============================================================================\n",
    "\n",
    "class DarkTheme:\n",
    "    \"\"\"Dark theme color palette.\"\"\"\n",
    "    BACKGROUND = '#1a1a2e'\n",
    "    PANEL = '#16213e'\n",
    "    BLUE = '#4da6ff'\n",
    "    ORANGE = '#ff9f43'\n",
    "    GREEN = '#00d4aa'\n",
    "    RED = '#ff6b6b'\n",
    "    PURPLE = '#a855f7'\n",
    "    CYAN = '#00d4ff'\n",
    "    PINK = '#ff69b4'\n",
    "    HISTOGRAM = '#4a90d9'\n",
    "    GRID = '#3a3a5a'\n",
    "    TEXT = '#e0e0e0'\n",
    "    TEXT_DIM = '#a0a0a0'\n",
    "    GOLD = '#ffd700'\n",
    "    YELLOW = '#ffc107'\n",
    "\n",
    "\n",
    "class LightTheme:\n",
    "    \"\"\"Light theme color palette.\"\"\"\n",
    "    PRIMARY = '#1a3a5e'\n",
    "    SECONDARY = '#6a33f5'\n",
    "    ACCENT = '#00d4aa'\n",
    "    POSITIVE = '#00c853'\n",
    "    NEGATIVE = '#ff1744'\n",
    "    WARNING = '#ffc107'\n",
    "    NEUTRAL = '#78909c'\n",
    "    GOLD = '#ffd700'\n",
    "\n",
    "\n",
    "def setup_dark_theme():\n",
    "    \"\"\"Apply dark theme to matplotlib.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': DarkTheme.BACKGROUND,\n",
    "        'axes.facecolor': DarkTheme.PANEL,\n",
    "        'axes.edgecolor': DarkTheme.GRID,\n",
    "        'axes.labelcolor': DarkTheme.TEXT,\n",
    "        'text.color': DarkTheme.TEXT,\n",
    "        'xtick.color': DarkTheme.TEXT,\n",
    "        'ytick.color': DarkTheme.TEXT,\n",
    "        'grid.color': DarkTheme.GRID,\n",
    "        'grid.alpha': 0.3,\n",
    "        'legend.facecolor': DarkTheme.PANEL,\n",
    "        'legend.edgecolor': DarkTheme.GRID,\n",
    "        'legend.labelcolor': DarkTheme.TEXT,\n",
    "    })\n",
    "\n",
    "\n",
    "def reset_light_theme():\n",
    "    \"\"\"Reset to light theme.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 11,\n",
    "        'figure.facecolor': 'white',\n",
    "        'axes.facecolor': 'white',\n",
    "        'axes.spines.top': False,\n",
    "        'axes.spines.right': False,\n",
    "    })\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# WEEKEND THETA CONFIGURATION (NOW ACTUALLY WIRED - FIX #2)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class WeekendThetaConfig:\n",
    "    \"\"\"Weekend theta decay configuration - NOW ACTUALLY AFFECTS PNL.\"\"\"\n",
    "    enabled: bool = True\n",
    "    weekend_factor: float = 3.0  # Base factor for Friâ†’Mon decay\n",
    "    dte_scaling_enabled: bool = True\n",
    "    dte_7_factor: float = 3.5    # Weeklies: more theta decay\n",
    "    dte_14_factor: float = 3.0   # 2-week options\n",
    "    dte_30_factor: float = 2.5   # Monthlies: less theta impact\n",
    "    long_weekend_factor: float = 4.0  # Holidays\n",
    "    test_mode: bool = False\n",
    "    test_factors: List[float] = field(default_factory=lambda: [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0])\n",
    "\n",
    "    def get_weekend_factor(self, dte: int = 7, is_long_weekend: bool = False) -> float:\n",
    "        \"\"\"Get weekend decay factor based on DTE.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return 1.0\n",
    "        if is_long_weekend:\n",
    "            return self.long_weekend_factor\n",
    "        if not self.dte_scaling_enabled:\n",
    "            return self.weekend_factor\n",
    "        if dte <= 7:\n",
    "            return self.dte_7_factor\n",
    "        elif dte <= 14:\n",
    "            return self.dte_14_factor\n",
    "        elif dte <= 30:\n",
    "            return self.dte_30_factor\n",
    "        else:\n",
    "            return 2.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STRATEGY LEVERAGE CONFIG (FIX #4 - Different leverage per strategy)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class StrategyLeverageConfig:\n",
    "    \"\"\"\n",
    "    Different leverage/scaling per option strategy type.\n",
    "\n",
    "    Rationale:\n",
    "    - Short strangles: higher leverage (selling premium both sides)\n",
    "    - Iron condors: moderate (defined risk)\n",
    "    - Vertical spreads: lower (single direction, defined risk)\n",
    "    - Naked puts/calls: high leverage but capped\n",
    "    \"\"\"\n",
    "    bull_put_spread: float = 1.0      # Defined risk, moderate\n",
    "    bear_call_spread: float = 1.0     # Defined risk, moderate\n",
    "    iron_condor: float = 1.5          # Premium collection both sides\n",
    "    short_put: float = 1.2            # Naked, capped\n",
    "    short_call: float = 1.2           # Naked, capped\n",
    "    strangle: float = 1.8             # Most aggressive premium selling\n",
    "    cash: float = 0.0                 # No position\n",
    "\n",
    "    def get_leverage(self, strategy: str) -> float:\n",
    "        \"\"\"Get leverage multiplier for strategy.\"\"\"\n",
    "        leverage_map = {\n",
    "            'BullPutSpread': self.bull_put_spread,\n",
    "            'BearCallSpread': self.bear_call_spread,\n",
    "            'IronCondor': self.iron_condor,\n",
    "            'ShortPut': self.short_put,\n",
    "            'ShortCall': self.short_call,\n",
    "            'Strangle': self.strangle,\n",
    "            'Cash': self.cash\n",
    "        }\n",
    "        return leverage_map.get(strategy, 1.0)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ScientificConfig:\n",
    "    \"\"\"\n",
    "    Configuration for Scientific Options Framework v4.9 TRUTH MODE.\n",
    "\n",
    "    v4.9 TRUTH MODE - REALISTIC CALIBRATION:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    â€¢ Lower target_vol (0.08)\n",
    "    â€¢ Higher transaction costs\n",
    "    â€¢ Tighter drawdown limits\n",
    "    â€¢ Stricter ex-ante gates\n",
    "    â€¢ Reduced position sizes\n",
    "\n",
    "    GOAL: Expose real structural alpha, not parameter-driven upside.\n",
    "    \"\"\"\n",
    "\n",
    "    # Paths\n",
    "    data_dir: Path = field(default_factory=lambda: Path(\"/Users/jasongu/Downloads/DataSet2\"))\n",
    "    report_dir: Path = field(default_factory=lambda: Path(\"/Users/jasongu/Downloads/DataSet2/Reports\"))\n",
    "\n",
    "    # Logging\n",
    "    logging: LoggingConfig = field(default_factory=LoggingConfig)\n",
    "\n",
    "    # Weekend theta (WIRED into PnL)\n",
    "    weekend_theta: WeekendThetaConfig = field(default_factory=WeekendThetaConfig)\n",
    "\n",
    "    # Strategy leverage (WIRED into position sizing)\n",
    "    strategy_leverage: StrategyLeverageConfig = field(default_factory=StrategyLeverageConfig)\n",
    "\n",
    "    # Account (for equity curve tracking, not actual capital constraints)\n",
    "    account_size: float = 100_000  # Initial notional for equity curve\n",
    "\n",
    "    # Walk-forward (ACTIVELY USED)\n",
    "    train_window: int = 252 * 2  # 2 years\n",
    "    test_window: int = 21        # 1 month\n",
    "    min_train_size: int = 252\n",
    "\n",
    "    # ML (ACTIVELY USED) - v4.9 TRUTH MODE: More conservative\n",
    "    ml_regularization: float = 0.1\n",
    "    ml_model_type: str = 'gradient_boosting'\n",
    "    ml_n_estimators: int = 80   # v4.9: Reduced from 100\n",
    "    ml_max_depth: int = 3       # v4.9: Shallower trees (was 4)\n",
    "    ml_learning_rate: float = 0.03  # v4.9: Reduced from 0.05\n",
    "    ml_min_probability: float = 0.58  # v4.9: Higher bar (was 0.55)\n",
    "    ml_features: List[str] = field(default_factory=lambda: [\n",
    "        'ret_1', 'ret_5', 'vol_20', 'vol_parkinson', 'vol_gk',\n",
    "        'rsi_14', 'momentum', 'price_to_sma_20',\n",
    "        'vol_percentile', 'vol_of_vol', 'atr_14',\n",
    "        'skew_20_shrunk', 'kurt_20_shrunk'\n",
    "    ])\n",
    "\n",
    "    # HMM (ACTIVELY USED)\n",
    "    hmm_n_states: int = 3\n",
    "    hmm_n_iter: int = 100\n",
    "\n",
    "    # Vol Percentile - v4.9 TRUTH MODE: More selective\n",
    "    vol_percentile_threshold: float = 0.70  # v4.9: Slightly less selective (was 0.75)\n",
    "    vol_percentile_lookback: int = 252\n",
    "    extreme_vol_cutoff: float = 0.995  # v4.9: Only TRUE crises (was 0.98)\n",
    "\n",
    "    # Risk - v4.9 TRUTH MODE: More conservative\n",
    "    target_vol: float = 0.08  # v4.9: Realistic fund level (was 0.10)\n",
    "    var_confidence: float = 0.95\n",
    "    max_drawdown_limit: float = -0.20  # For reporting\n",
    "    max_position_size: float = 0.25  # v4.9: Reduced leverage (was 0.40)\n",
    "    vol_smoothing_window: int = 60\n",
    "\n",
    "    # v4.9 TRUTH MODE: Tighter drawdown discipline\n",
    "    dd_half_size_threshold: float = -0.07  # v4.9: Tighter (was -0.10)\n",
    "    dd_flat_threshold: float = -0.15  # v4.9: Tighter (was -0.20)\n",
    "\n",
    "    # v4.9 TRUTH MODE: Tighter ex-ante gates\n",
    "    large_move_threshold: float = 2.5  # v4.9: Tighter (was 2.0)\n",
    "    vol_of_vol_threshold: float = 0.25  # v4.9: Vol must REALLY explode (was 0.15)\n",
    "\n",
    "    # Turnover control - v4.9: More reactive\n",
    "    strategy_rebalance_days: int = 3  # v4.9: More reactive (was 5)\n",
    "    atr_sideways_threshold: float = 0.002\n",
    "\n",
    "    # Options (used for DTE in weekend theta)\n",
    "    risk_free_rate: float = 0.05\n",
    "    dte_weekly: int = 7\n",
    "    dte_monthly: int = 30\n",
    "    use_weekly: bool = True\n",
    "\n",
    "    # Transaction costs - v4.9 TRUTH MODE: Higher realistic costs\n",
    "    tx_commission: float = 0.0008  # v4.9: Higher (was 0.0005*0.95)\n",
    "    tx_spread: float = 0.0012     # v4.9: Higher (was 0.001*0.95)\n",
    "    tx_slippage: float = 0.0007   # v4.9: Higher (was 0.0005*0.95)\n",
    "\n",
    "    # Forecast (for analysis columns)\n",
    "    forecast_horizon: int = 5\n",
    "\n",
    "    # Reliability diagram settings\n",
    "    reliability_n_bins: int = 10\n",
    "\n",
    "    # Higher moment shrinkage (ACTIVELY USED)\n",
    "    moment_shrinkage_lambda: float = 0.5\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.report_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if self.logging.save_to_file and self.logging.log_file_path is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.logging.log_file_path = self.report_dir / f\"backtest_{timestamp}.log\"\n",
    "\n",
    "    def copy(self) -> 'ScientificConfig':\n",
    "        \"\"\"\n",
    "        Create a deep copy of the configuration.\n",
    "\n",
    "        v4.1 NEW: Useful for parameter sweeps and testing.\n",
    "        \"\"\"\n",
    "        import copy\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def with_overrides(self, **kwargs) -> 'ScientificConfig':\n",
    "        \"\"\"\n",
    "        Create a copy with specific overrides.\n",
    "\n",
    "        v4.1 NEW: Convenient for parameter testing.\n",
    "\n",
    "        Example:\n",
    "            test_config = config.with_overrides(\n",
    "                train_window=504,\n",
    "                target_vol=0.15\n",
    "            )\n",
    "        \"\"\"\n",
    "        import copy\n",
    "        new_config = copy.deepcopy(self)\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(new_config, key):\n",
    "                setattr(new_config, key, value)\n",
    "            elif '.' in key:\n",
    "                # Handle nested attributes like 'weekend_theta.weekend_factor'\n",
    "                parts = key.split('.', 1)\n",
    "                if hasattr(new_config, parts[0]):\n",
    "                    parent = getattr(new_config, parts[0])\n",
    "                    if hasattr(parent, parts[1]):\n",
    "                        setattr(parent, parts[1], value)\n",
    "            else:\n",
    "                raise AttributeError(f\"ScientificConfig has no attribute '{key}'\")\n",
    "\n",
    "        return new_config\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED DATA LOADER (NEW: Parkinson, GK vol, ATR, shrunk moments)\n",
    "# =============================================================================\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Load and preprocess market data with enhanced features.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ScientificConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load(self, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data for a ticker.\"\"\"\n",
    "        files = list(self.config.data_dir.glob(f\"*{ticker.split('.')[0]}*.csv\"))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No data file found for {ticker}\")\n",
    "\n",
    "        df = pd.read_csv(files[0], parse_dates=['timestamp'])\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "\n",
    "        daily = df.resample('D').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "        return daily\n",
    "\n",
    "    def add_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add technical features including new estimators.\"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # =====================================================================\n",
    "        # BASIC RETURNS\n",
    "        # =====================================================================\n",
    "        df['ret_1'] = df['close'].pct_change(1)\n",
    "        df['ret_5'] = df['close'].pct_change(5)\n",
    "        df['ret_20'] = df['close'].pct_change(20)\n",
    "\n",
    "        # =====================================================================\n",
    "        # VOLATILITY ESTIMATORS (ENHANCED)\n",
    "        # =====================================================================\n",
    "\n",
    "        # 1. Close-to-close volatility (original)\n",
    "        df['vol_20'] = df['ret_1'].rolling(20).std() * np.sqrt(252)\n",
    "        df['vol_60'] = df['ret_1'].rolling(60).std() * np.sqrt(252)\n",
    "\n",
    "        # 2. Parkinson volatility (uses high-low range) - NEW\n",
    "        # More efficient than close-to-close for continuous processes\n",
    "        log_hl = np.log(df['high'] / df['low'])\n",
    "        df['vol_parkinson'] = np.sqrt(\n",
    "            (1 / (4 * np.log(2))) * (log_hl ** 2).rolling(20).mean() * 252\n",
    "        )\n",
    "\n",
    "        # 3. Garman-Klass volatility (uses OHLC) - NEW\n",
    "        # Most efficient estimator using all OHLC data\n",
    "        log_hl = np.log(df['high'] / df['low'])\n",
    "        log_co = np.log(df['close'] / df['open'])\n",
    "        df['vol_gk'] = np.sqrt(\n",
    "            (0.5 * log_hl**2 - (2*np.log(2) - 1) * log_co**2).rolling(20).mean() * 252\n",
    "        )\n",
    "\n",
    "        # 4. ATR (Average True Range) - NEW\n",
    "        high_low = df['high'] - df['low']\n",
    "        high_close = np.abs(df['high'] - df['close'].shift(1))\n",
    "        low_close = np.abs(df['low'] - df['close'].shift(1))\n",
    "        true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "        df['atr_14'] = true_range.rolling(14).mean()\n",
    "        df['atr_pct'] = df['atr_14'] / df['close']  # ATR as % of price\n",
    "\n",
    "        # 5. Vol of vol (preserved)\n",
    "        df['vol_of_vol'] = df['vol_20'].rolling(20).std()\n",
    "\n",
    "        # =====================================================================\n",
    "        # MOMENTUM & TREND\n",
    "        # =====================================================================\n",
    "\n",
    "        # RSI\n",
    "        delta = df['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "        rs = gain / loss.replace(0, np.nan)\n",
    "        df['rsi_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        # Momentum\n",
    "        df['momentum'] = df['close'] / df['close'].shift(20) - 1\n",
    "\n",
    "        # SMA\n",
    "        df['sma_20'] = df['close'].rolling(20).mean()\n",
    "        df['price_to_sma_20'] = df['close'] / df['sma_20'] - 1\n",
    "\n",
    "        # =====================================================================\n",
    "        # HIGHER MOMENTS WITH SHRINKAGE (FIX - more robust)\n",
    "        # =====================================================================\n",
    "\n",
    "        # Raw moments\n",
    "        df['skew_20_raw'] = df['ret_1'].rolling(20).apply(skew, raw=True)\n",
    "        df['kurt_20_raw'] = df['ret_1'].rolling(20).apply(kurtosis, raw=True)\n",
    "\n",
    "        # Shrunk moments (toward 0 for skew, toward 0 for excess kurtosis)\n",
    "        # Formula: shrunk = raw / sqrt(1 + lambda)\n",
    "        shrink_factor = np.sqrt(1 + self.config.moment_shrinkage_lambda)\n",
    "        df['skew_20_shrunk'] = df['skew_20_raw'] / shrink_factor\n",
    "        df['kurt_20_shrunk'] = df['kurt_20_raw'] / shrink_factor\n",
    "\n",
    "        # Also compute on longer window (more stable)\n",
    "        df['skew_60'] = df['ret_1'].rolling(60).apply(skew, raw=True)\n",
    "        df['kurt_60'] = df['ret_1'].rolling(60).apply(kurtosis, raw=True)\n",
    "\n",
    "        # =====================================================================\n",
    "        # DAY OF WEEK (for weekend theta)\n",
    "        # =====================================================================\n",
    "        df['day_of_week'] = df.index.dayofweek  # 0=Monday, 4=Friday\n",
    "        df['is_friday'] = (df['day_of_week'] == 4).astype(int)\n",
    "\n",
    "        return df.dropna()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HMM REGIME DETECTOR (FIX #1 - No more leakage)\n",
    "# =============================================================================\n",
    "\n",
    "class HMMRegimeDetector:\n",
    "    \"\"\"\n",
    "    Hidden Markov Model for regime detection.\n",
    "\n",
    "    FIX #1 (v4.0): Now properly separates fit (train) from predict (test).\n",
    "    FIX 1.2 (v4.2): Maps states to Bull/Neutral/Bear based on actual return/vol properties.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_states: int = 3, n_iter: int = 200):\n",
    "        self.n_states = n_states\n",
    "        self.n_iter = n_iter\n",
    "        self.model = None\n",
    "        self.state_names = ['Bull', 'Neutral', 'Bear'][:n_states]\n",
    "        self._feature_mean = None\n",
    "        self._feature_std = None\n",
    "        # v4.2: State mapping based on properties\n",
    "        self._state_mapping = None  # Maps raw state index to semantic name\n",
    "        self._state_stats = {}  # Statistics per state\n",
    "\n",
    "    def _prepare_features(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Prepare feature matrix for HMM.\"\"\"\n",
    "        features = []\n",
    "        for col in ['vol_20', 'vol_of_vol', 'skew_20_shrunk', 'ret_5']:\n",
    "            if col in df.columns:\n",
    "                features.append(df[col].fillna(method='ffill').fillna(0).values)\n",
    "\n",
    "        if not features:\n",
    "            features = [df['ret_1'].fillna(0).values]\n",
    "\n",
    "        return np.column_stack(features)\n",
    "\n",
    "    def _compute_state_mapping(self, train_df: pd.DataFrame, raw_states: np.ndarray):\n",
    "        \"\"\"\n",
    "        FIX 1.2: Compute mapping from raw HMM states to semantic regime names.\n",
    "\n",
    "        Maps states based on mean return:\n",
    "        - Highest mean return â†’ Bull (state 0)\n",
    "        - Middle mean return â†’ Neutral (state 1)\n",
    "        - Lowest mean return â†’ Bear (state 2)\n",
    "\n",
    "        This ensures regime labels match actual market behavior.\n",
    "        \"\"\"\n",
    "        if 'ret_1' not in train_df.columns:\n",
    "            # Fallback: use raw states as-is\n",
    "            self._state_mapping = {i: i for i in range(self.n_states)}\n",
    "            return\n",
    "\n",
    "        returns = train_df['ret_1'].values\n",
    "        vol = train_df['vol_20'].values if 'vol_20' in train_df.columns else np.ones(len(train_df)) * 0.15\n",
    "\n",
    "        # Compute per-state statistics\n",
    "        state_stats = []\n",
    "        for state in range(self.n_states):\n",
    "            mask = raw_states == state\n",
    "            if mask.sum() > 0:\n",
    "                mean_ret = np.nanmean(returns[mask])\n",
    "                mean_vol = np.nanmean(vol[mask])\n",
    "                count = mask.sum()\n",
    "            else:\n",
    "                mean_ret = 0.0\n",
    "                mean_vol = 0.15\n",
    "                count = 0\n",
    "\n",
    "            state_stats.append({\n",
    "                'raw_state': state,\n",
    "                'mean_return': mean_ret,\n",
    "                'mean_vol': mean_vol,\n",
    "                'count': count\n",
    "            })\n",
    "\n",
    "        # Sort by mean return (descending) to assign semantic names\n",
    "        sorted_stats = sorted(state_stats, key=lambda x: x['mean_return'], reverse=True)\n",
    "\n",
    "        # Create mapping: raw_state â†’ semantic_state\n",
    "        # Highest return = Bull (0), Middle = Neutral (1), Lowest = Bear (2)\n",
    "        self._state_mapping = {}\n",
    "        semantic_names = ['Bull', 'Neutral', 'Bear']\n",
    "\n",
    "        for semantic_idx, stats in enumerate(sorted_stats):\n",
    "            raw_state = stats['raw_state']\n",
    "            self._state_mapping[raw_state] = semantic_idx\n",
    "            self._state_stats[semantic_idx] = {\n",
    "                'name': semantic_names[min(semantic_idx, len(semantic_names)-1)],\n",
    "                'mean_return': stats['mean_return'],\n",
    "                'mean_vol': stats['mean_vol'],\n",
    "                'count': stats['count']\n",
    "            }\n",
    "\n",
    "        # Update state_names to reflect actual mapping\n",
    "        self.state_names = [semantic_names[i] for i in range(min(self.n_states, 3))]\n",
    "\n",
    "    def _apply_state_mapping(self, raw_states: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply state mapping to convert raw HMM states to semantic states.\"\"\"\n",
    "        if self._state_mapping is None:\n",
    "            return raw_states\n",
    "\n",
    "        mapped = np.zeros_like(raw_states)\n",
    "        for raw, semantic in self._state_mapping.items():\n",
    "            mapped[raw_states == raw] = semantic\n",
    "        return mapped\n",
    "\n",
    "    def get_state_statistics(self) -> Dict[int, Dict]:\n",
    "        \"\"\"Return computed statistics per regime for analysis/debugging.\"\"\"\n",
    "        return self._state_stats\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame) -> 'HMMRegimeDetector':\n",
    "        \"\"\"\n",
    "        Fit HMM on training data ONLY.\n",
    "\n",
    "        FIX #1: Only uses training data to learn the model.\n",
    "        FIX 1.2 (v4.2): Computes stateâ†’regime mapping based on return/vol properties.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from hmmlearn import hmm\n",
    "\n",
    "            X = self._prepare_features(train_df)\n",
    "\n",
    "            # Store normalization parameters from training data\n",
    "            self._feature_mean = np.nanmean(X, axis=0)\n",
    "            self._feature_std = np.nanstd(X, axis=0) + 1e-8\n",
    "\n",
    "            # Normalize\n",
    "            X_norm = (X - self._feature_mean) / self._feature_std\n",
    "            X_norm = np.nan_to_num(X_norm, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "            # Fit model\n",
    "            self.model = hmm.GaussianHMM(\n",
    "                n_components=self.n_states,\n",
    "                covariance_type='full',\n",
    "                n_iter=self.n_iter,\n",
    "                random_state=42\n",
    "            )\n",
    "            self.model.fit(X_norm)\n",
    "\n",
    "            # FIX 1.2: Compute state mapping based on actual return/vol properties\n",
    "            raw_states = self.model.predict(X_norm)\n",
    "            self._compute_state_mapping(train_df, raw_states)\n",
    "\n",
    "        except ImportError:\n",
    "            # Fallback: store volatility percentiles from training\n",
    "            vol = train_df['vol_20'].fillna(method='ffill').values if 'vol_20' in train_df.columns else np.ones(len(train_df)) * 0.15\n",
    "            self._vol_p33 = np.percentile(vol, 33)\n",
    "            self._vol_p67 = np.percentile(vol, 67)\n",
    "            self.model = None\n",
    "            # Fallback mapping: low vol = Bull, high vol = Bear\n",
    "            self._state_mapping = {0: 0, 1: 1, 2: 2}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Predict states on test data using model fitted on training data.\n",
    "\n",
    "        No future information leakage.\n",
    "        FIX 1.2 (v4.2): Returns semantically-mapped states (Bull=0, Neutral=1, Bear=2).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from hmmlearn import hmm\n",
    "\n",
    "            if self.model is None:\n",
    "                raise ImportError(\"Model not fitted\")\n",
    "\n",
    "            X = self._prepare_features(test_df)\n",
    "\n",
    "            # Use training normalization parameters (not test statistics!)\n",
    "            X_norm = (X - self._feature_mean) / self._feature_std\n",
    "            X_norm = np.nan_to_num(X_norm, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "            raw_states = self.model.predict(X_norm)\n",
    "            raw_probs = self.model.predict_proba(X_norm)\n",
    "\n",
    "            # FIX 1.2: Apply semantic mapping so Bull=0, Neutral=1, Bear=2\n",
    "            states = self._apply_state_mapping(raw_states)\n",
    "\n",
    "            # Reorder probability columns to match mapped states\n",
    "            probs = np.zeros_like(raw_probs)\n",
    "            if self._state_mapping is not None:\n",
    "                for raw, semantic in self._state_mapping.items():\n",
    "                    probs[:, semantic] = raw_probs[:, raw]\n",
    "            else:\n",
    "                probs = raw_probs\n",
    "\n",
    "            return states, probs\n",
    "\n",
    "        except (ImportError, AttributeError):\n",
    "            # Fallback using training percentiles\n",
    "            # FIX 2.4: Guard against missing attributes from failed fit()\n",
    "            if not hasattr(self, '_vol_p33') or not hasattr(self, '_vol_p67'):\n",
    "                # Safe defaults if percentiles weren't computed\n",
    "                self._vol_p33 = 0.10\n",
    "                self._vol_p67 = 0.20\n",
    "\n",
    "            vol = test_df['vol_20'].fillna(method='ffill').values if 'vol_20' in test_df.columns else np.ones(len(test_df)) * 0.15\n",
    "\n",
    "            states = np.ones(len(test_df), dtype=int)  # Default neutral\n",
    "            states[vol < self._vol_p33] = 0  # Bull (low vol)\n",
    "            states[vol >= self._vol_p67] = 2  # Bear (high vol)\n",
    "\n",
    "            probs = np.zeros((len(test_df), self.n_states))\n",
    "            for i, s in enumerate(states):\n",
    "                probs[i, s] = 0.7\n",
    "                for j in range(self.n_states):\n",
    "                    if j != s:\n",
    "                        probs[i, j] = 0.3 / (self.n_states - 1)\n",
    "\n",
    "            return states, probs\n",
    "\n",
    "    def fit_predict(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Legacy method for single-pass (used for training visualization).\n",
    "        For proper walk-forward, use fit() then predict() separately.\n",
    "        \"\"\"\n",
    "        self.fit(df)\n",
    "        return self.predict(df)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ML SIGNAL GENERATOR (FIX #3 - OOS AUC, not train AUC)\n",
    "# =============================================================================\n",
    "\n",
    "class MLSignalGenerator:\n",
    "    \"\"\"\n",
    "    Machine learning signal generator with proper OOS tracking.\n",
    "\n",
    "    FIX #3 (v4.0): Now tracks and reports test AUC, not train AUC.\n",
    "    FIX 1.1 (v4.2): Drops last training row to prevent label leakage at window boundaries.\n",
    "    v4.3 ENHANCEMENT: Uses GradientBoosting/RandomForest for better predictive power.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ScientificConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "        # Track predictions and outcomes for calibration\n",
    "        self.all_predictions = []\n",
    "        self.all_outcomes = []\n",
    "        self.feature_importances = {}\n",
    "\n",
    "        # NEW: Track per-window test AUC\n",
    "        self.window_test_aucs = []\n",
    "        self.all_regimes = []  # For regime-specific analysis\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"\n",
    "        v4.3: Create ML model based on config.ml_model_type.\n",
    "        Options: 'logistic', 'gradient_boosting', 'random_forest'\n",
    "        \"\"\"\n",
    "        model_type = getattr(self.config, 'ml_model_type', 'gradient_boosting')\n",
    "\n",
    "        if model_type == 'gradient_boosting':\n",
    "            try:\n",
    "                from sklearn.ensemble import GradientBoostingClassifier\n",
    "                return GradientBoostingClassifier(\n",
    "                    n_estimators=getattr(self.config, 'ml_n_estimators', 100),\n",
    "                    max_depth=getattr(self.config, 'ml_max_depth', 4),\n",
    "                    learning_rate=getattr(self.config, 'ml_learning_rate', 0.05),\n",
    "                    subsample=0.8,\n",
    "                    min_samples_split=20,\n",
    "                    min_samples_leaf=10,\n",
    "                    random_state=42\n",
    "                )\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "        elif model_type == 'random_forest':\n",
    "            try:\n",
    "                from sklearn.ensemble import RandomForestClassifier\n",
    "                return RandomForestClassifier(\n",
    "                    n_estimators=getattr(self.config, 'ml_n_estimators', 100),\n",
    "                    max_depth=getattr(self.config, 'ml_max_depth', 4),\n",
    "                    min_samples_split=20,\n",
    "                    min_samples_leaf=10,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "        # Fallback to logistic regression\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression(\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            C=1/self.config.ml_regularization,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def fit_predict(self, train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                    test_regimes: np.ndarray = None) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Fit model and predict, tracking OOS performance.\n",
    "\n",
    "        Returns: (predicted_probabilities, test_auc)\n",
    "\n",
    "        FIX #3: Now returns TEST AUC, not train AUC.\n",
    "        FIX 1.1 (v4.2): Drops last training row to prevent label leakage.\n",
    "        v4.3: Uses ensemble models for better AUC.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            from sklearn.metrics import roc_auc_score\n",
    "\n",
    "            feature_cols = [c for c in self.config.ml_features if c in train_df.columns]\n",
    "            if not feature_cols:\n",
    "                return np.zeros(len(test_df)), 0.5\n",
    "\n",
    "            X_train = train_df[feature_cols].fillna(0).values\n",
    "            X_test = test_df[feature_cols].fillna(0).values\n",
    "\n",
    "            # Labels: next day's return direction\n",
    "            y_train = (train_df['ret_1'].shift(-1) > 0).astype(int).fillna(0).values\n",
    "            y_test = (test_df['ret_1'].shift(-1) > 0).astype(int).fillna(0).values\n",
    "\n",
    "            # FIX 1.1: Drop the last training row - its label uses the first test day's return\n",
    "            if len(X_train) > 10:\n",
    "                X_train = X_train[:-1]\n",
    "                y_train = y_train[:-1]\n",
    "\n",
    "            # Standardize using TRAINING statistics only\n",
    "            self.scaler = StandardScaler()\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "            # v4.3: Create model based on config\n",
    "            self.model = self._create_model()\n",
    "            self.model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # Predict on test\n",
    "            probs = self.model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "            # Store for calibration analysis (excluding last point which has no outcome)\n",
    "            for i in range(len(probs) - 1):\n",
    "                self.all_predictions.append(probs[i])\n",
    "                self.all_outcomes.append(y_test[i])\n",
    "                if test_regimes is not None and i < len(test_regimes):\n",
    "                    self.all_regimes.append(test_regimes[i])\n",
    "\n",
    "            # Store feature importances (handle different model types)\n",
    "            if hasattr(self.model, 'feature_importances_'):\n",
    "                # GradientBoosting, RandomForest\n",
    "                importances = self.model.feature_importances_\n",
    "            elif hasattr(self.model, 'coef_'):\n",
    "                # LogisticRegression\n",
    "                importances = np.abs(self.model.coef_[0])\n",
    "            else:\n",
    "                importances = np.ones(len(feature_cols)) / len(feature_cols)\n",
    "\n",
    "            for i, col in enumerate(feature_cols):\n",
    "                if col not in self.feature_importances:\n",
    "                    self.feature_importances[col] = []\n",
    "                self.feature_importances[col].append(importances[i])\n",
    "\n",
    "            # FIX #3: Compute TEST AUC (not train AUC)\n",
    "            # Exclude last point since we don't have its outcome yet\n",
    "            valid_mask = np.arange(len(probs) - 1)\n",
    "            if len(valid_mask) > 10 and len(np.unique(y_test[valid_mask])) > 1:\n",
    "                test_auc = roc_auc_score(y_test[valid_mask], probs[valid_mask])\n",
    "            else:\n",
    "                test_auc = 0.5\n",
    "\n",
    "            self.window_test_aucs.append(test_auc)\n",
    "\n",
    "            return probs, test_auc\n",
    "\n",
    "        except ImportError:\n",
    "            return np.ones(len(test_df)) * 0.5, 0.5\n",
    "\n",
    "    def get_calibration_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Return all predictions and outcomes for calibration analysis.\"\"\"\n",
    "        return np.array(self.all_predictions), np.array(self.all_outcomes)\n",
    "\n",
    "    def get_global_oos_auc(self) -> float:\n",
    "        \"\"\"Compute overall OOS AUC across all windows.\"\"\"\n",
    "        if len(self.all_predictions) < 10:\n",
    "            return 0.5\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score\n",
    "            preds = np.array(self.all_predictions)\n",
    "            outcomes = np.array(self.all_outcomes)\n",
    "            if len(np.unique(outcomes)) < 2:\n",
    "                return 0.5\n",
    "            return roc_auc_score(outcomes, preds)\n",
    "        except:\n",
    "            return 0.5\n",
    "\n",
    "    def get_mean_window_auc(self) -> float:\n",
    "        \"\"\"Get mean test AUC across all windows.\"\"\"\n",
    "        if not self.window_test_aucs:\n",
    "            return 0.5\n",
    "        return np.mean(self.window_test_aucs)\n",
    "\n",
    "    def get_average_window_auc(self) -> float:\n",
    "        \"\"\"Alias for get_mean_window_auc (backward compatibility).\"\"\"\n",
    "        return self.get_mean_window_auc()\n",
    "\n",
    "    def get_calibration_by_regime(self) -> Dict[int, Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Get predictions/outcomes separated by regime for analysis.\"\"\"\n",
    "        if not self.all_regimes:\n",
    "            return {}\n",
    "\n",
    "        result = {}\n",
    "        preds = np.array(self.all_predictions)\n",
    "        outcomes = np.array(self.all_outcomes)\n",
    "        regimes = np.array(self.all_regimes[:len(preds)])\n",
    "\n",
    "        for regime in np.unique(regimes):\n",
    "            mask = regimes == regime\n",
    "            result[regime] = (preds[mask], outcomes[mask])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def reset_calibration_data(self):\n",
    "        \"\"\"Reset calibration tracking for new backtest.\"\"\"\n",
    "        self.all_predictions = []\n",
    "        self.all_outcomes = []\n",
    "        self.window_test_aucs = []\n",
    "        self.all_regimes = []\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# VOL PERCENTILE ENGINE (RENAMED FROM VRP - FIX #6)\n",
    "# =============================================================================\n",
    "\n",
    "class VolPercentileEngine:\n",
    "    \"\"\"\n",
    "    Volatility Percentile calculator.\n",
    "\n",
    "    FIX #6: Renamed from VRP since we don't have implied vol.\n",
    "    This computes: current realized vol percentile vs historical distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ScientificConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def calculate_vol_percentile(self, train_df: pd.DataFrame,\n",
    "                                   test_df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate realized vol percentile using TRAINING distribution.\n",
    "\n",
    "        Returns: array of percentiles [0, 1] for each test day.\n",
    "\n",
    "        v4.1 OPTIMIZATION: Uses np.searchsorted for O(N*log(M)) instead of O(N*M).\n",
    "        \"\"\"\n",
    "        vol_col = 'vol_20'\n",
    "        if vol_col not in train_df.columns:\n",
    "            return np.ones(len(test_df)) * 0.5\n",
    "\n",
    "        # Use training period vol distribution\n",
    "        historical_vol = train_df[vol_col].dropna().values\n",
    "\n",
    "        if len(historical_vol) == 0:\n",
    "            return np.ones(len(test_df)) * 0.5\n",
    "\n",
    "        # Get test period vol\n",
    "        test_vol = test_df[vol_col].fillna(method='ffill').values\n",
    "\n",
    "        # OPTIMIZED: Use searchsorted for O(n*log(m)) instead of O(n*m)\n",
    "        sorted_vol = np.sort(historical_vol)\n",
    "        indices = np.searchsorted(sorted_vol, test_vol)\n",
    "        percentiles = indices / len(sorted_vol)\n",
    "\n",
    "        return percentiles\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CALIBRATION METRICS (Preserved from v3)\n",
    "# =============================================================================\n",
    "\n",
    "class CalibrationMetrics:\n",
    "    \"\"\"Calibration metrics for probability predictions (ISL p. 455).\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_calibration_curve(predictions: np.ndarray, outcomes: np.ndarray,\n",
    "                                   n_bins: int = 10) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Compute calibration curve data for reliability diagram.\"\"\"\n",
    "        if len(predictions) == 0 or len(outcomes) == 0:\n",
    "            return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        outcomes = np.array(outcomes)\n",
    "\n",
    "        bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "        bin_indices = np.digitize(predictions, bin_edges[1:-1])\n",
    "\n",
    "        mean_predicted = []\n",
    "        fraction_positive = []\n",
    "        bin_counts = []\n",
    "\n",
    "        for i in range(n_bins):\n",
    "            mask = bin_indices == i\n",
    "            if mask.sum() > 0:\n",
    "                mean_predicted.append(predictions[mask].mean())\n",
    "                fraction_positive.append(outcomes[mask].mean())\n",
    "                bin_counts.append(mask.sum())\n",
    "            else:\n",
    "                mean_predicted.append(np.nan)\n",
    "                fraction_positive.append(np.nan)\n",
    "                bin_counts.append(0)\n",
    "\n",
    "        return np.array(mean_predicted), np.array(fraction_positive), np.array(bin_counts)\n",
    "\n",
    "    @staticmethod\n",
    "    def expected_calibration_error(predictions: np.ndarray, outcomes: np.ndarray,\n",
    "                                    n_bins: int = 10) -> float:\n",
    "        \"\"\"Compute Expected Calibration Error (ECE).\"\"\"\n",
    "        if len(predictions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        mean_pred, frac_pos, counts = CalibrationMetrics.compute_calibration_curve(\n",
    "            predictions, outcomes, n_bins\n",
    "        )\n",
    "\n",
    "        total = sum(counts)\n",
    "        if total == 0:\n",
    "            return 0.0\n",
    "\n",
    "        ece = 0.0\n",
    "        for i in range(len(counts)):\n",
    "            if counts[i] > 0 and not np.isnan(mean_pred[i]) and not np.isnan(frac_pos[i]):\n",
    "                weight = counts[i] / total\n",
    "                ece += weight * abs(frac_pos[i] - mean_pred[i])\n",
    "\n",
    "        return ece\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_calibration_error(predictions: np.ndarray, outcomes: np.ndarray,\n",
    "                                   n_bins: int = 10) -> float:\n",
    "        \"\"\"Compute Maximum Calibration Error (MCE).\"\"\"\n",
    "        if len(predictions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        mean_pred, frac_pos, counts = CalibrationMetrics.compute_calibration_curve(\n",
    "            predictions, outcomes, n_bins\n",
    "        )\n",
    "\n",
    "        mce = 0.0\n",
    "        for i in range(len(counts)):\n",
    "            if counts[i] > 0 and not np.isnan(mean_pred[i]) and not np.isnan(frac_pos[i]):\n",
    "                mce = max(mce, abs(frac_pos[i] - mean_pred[i]))\n",
    "\n",
    "        return mce\n",
    "\n",
    "    @staticmethod\n",
    "    def brier_score(predictions: np.ndarray, outcomes: np.ndarray) -> float:\n",
    "        \"\"\"Compute Brier Score.\"\"\"\n",
    "        if len(predictions) == 0:\n",
    "            return 0.0\n",
    "        return np.mean((np.array(predictions) - np.array(outcomes)) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def brier_skill_score(predictions: np.ndarray, outcomes: np.ndarray) -> float:\n",
    "        \"\"\"Compute Brier Skill Score relative to climatology.\"\"\"\n",
    "        if len(predictions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        bs = CalibrationMetrics.brier_score(predictions, outcomes)\n",
    "        base_rate = np.mean(outcomes)\n",
    "        bs_ref = np.mean((base_rate - np.array(outcomes)) ** 2)\n",
    "\n",
    "        if bs_ref == 0:\n",
    "            return 0.0\n",
    "\n",
    "        return 1 - (bs / bs_ref)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SHARPE STATISTICS (Preserved from v3)\n",
    "# =============================================================================\n",
    "\n",
    "class SharpeStatistics:\n",
    "    \"\"\"Statistical tests for Sharpe ratio significance.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def sharpe_ratio(returns: np.ndarray, risk_free_rate: float = 0.0,\n",
    "                     annualization: int = 252) -> float:\n",
    "        \"\"\"Calculate annualized Sharpe ratio.\"\"\"\n",
    "        if len(returns) == 0 or np.std(returns) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        excess_returns = returns - risk_free_rate / annualization\n",
    "        return np.mean(excess_returns) / np.std(excess_returns, ddof=1) * np.sqrt(annualization)\n",
    "\n",
    "    @staticmethod\n",
    "    def sharpe_standard_error(returns: np.ndarray, sharpe: float = None) -> float:\n",
    "        \"\"\"Calculate standard error of Sharpe ratio (Lo 2002).\"\"\"\n",
    "        n = len(returns)\n",
    "        if n < 2:\n",
    "            return float('inf')\n",
    "\n",
    "        if sharpe is None:\n",
    "            sharpe = SharpeStatistics.sharpe_ratio(returns)\n",
    "\n",
    "        sk = skew(returns) if len(returns) > 2 else 0\n",
    "        ku = kurtosis(returns) if len(returns) > 3 else 0\n",
    "\n",
    "        se_squared = (1 + 0.5 * sharpe**2 - sk * sharpe + (ku / 4) * sharpe**2) / (n - 1)\n",
    "\n",
    "        return np.sqrt(max(se_squared, 1e-10))\n",
    "\n",
    "    @staticmethod\n",
    "    def sharpe_ttest(returns: np.ndarray, null_sharpe: float = 0.0,\n",
    "                     risk_free_rate: float = 0.0, annualization: int = 252) -> Dict[str, float]:\n",
    "        \"\"\"Perform t-test for Sharpe ratio significance.\"\"\"\n",
    "        n = len(returns)\n",
    "        if n < 3:\n",
    "            return {\n",
    "                'sharpe': 0.0, 't_stat': 0.0, 'p_value': 1.0,\n",
    "                'se': float('inf'), 'df': 0, 'significant_5pct': False,\n",
    "                'significant_1pct': False\n",
    "            }\n",
    "\n",
    "        sharpe = SharpeStatistics.sharpe_ratio(returns, risk_free_rate, annualization)\n",
    "        se = SharpeStatistics.sharpe_standard_error(returns, sharpe)\n",
    "\n",
    "        t_stat = (sharpe - null_sharpe) / se if se > 0 else 0\n",
    "        df = n - 1\n",
    "        p_value = 2 * (1 - t_dist.cdf(abs(t_stat), df))\n",
    "\n",
    "        return {\n",
    "            'sharpe': sharpe,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'se': se,\n",
    "            'df': df,\n",
    "            'significant_5pct': p_value < 0.05,\n",
    "            'significant_1pct': p_value < 0.01,\n",
    "            'ci_95_lower': sharpe - 1.96 * se,\n",
    "            'ci_95_upper': sharpe + 1.96 * se\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def sharpe_difference_ttest(returns1: np.ndarray, returns2: np.ndarray,\n",
    "                                 risk_free_rate: float = 0.0,\n",
    "                                 annualization: int = 252) -> Dict[str, float]:\n",
    "        \"\"\"Test if two Sharpe ratios are significantly different (Jobson-Korkie).\"\"\"\n",
    "        n = min(len(returns1), len(returns2))\n",
    "        if n < 5:\n",
    "            return {\n",
    "                'sharpe1': 0.0, 'sharpe2': 0.0, 'difference': 0.0,\n",
    "                't_stat': 0.0, 'p_value': 1.0, 'significant_5pct': False\n",
    "            }\n",
    "\n",
    "        returns1 = returns1[:n]\n",
    "        returns2 = returns2[:n]\n",
    "\n",
    "        sharpe1 = SharpeStatistics.sharpe_ratio(returns1, risk_free_rate, annualization)\n",
    "        sharpe2 = SharpeStatistics.sharpe_ratio(returns2, risk_free_rate, annualization)\n",
    "\n",
    "        sig1, sig2 = np.std(returns1, ddof=1), np.std(returns2, ddof=1)\n",
    "\n",
    "        if sig1 == 0 or sig2 == 0:\n",
    "            return {\n",
    "                'sharpe1': sharpe1, 'sharpe2': sharpe2, 'difference': sharpe1 - sharpe2,\n",
    "                't_stat': 0.0, 'p_value': 1.0, 'significant_5pct': False\n",
    "            }\n",
    "\n",
    "        rho = np.corrcoef(returns1, returns2)[0, 1]\n",
    "\n",
    "        theta = (1/n) * (2 * (1 - rho) + 0.5 * (sharpe1**2 + sharpe2**2 -\n",
    "                 2 * sharpe1 * sharpe2 * rho**2))\n",
    "\n",
    "        se_diff = np.sqrt(theta) if theta > 0 else 1e-8\n",
    "        t_stat = (sharpe1 - sharpe2) / se_diff\n",
    "        p_value = 2 * (1 - norm.cdf(abs(t_stat)))\n",
    "\n",
    "        return {\n",
    "            'sharpe1': sharpe1,\n",
    "            'sharpe2': sharpe2,\n",
    "            'difference': sharpe1 - sharpe2,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'se_diff': se_diff,\n",
    "            'significant_5pct': p_value < 0.05,\n",
    "            'significant_1pct': p_value < 0.01\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def format_pvalue(p_value: float) -> str:\n",
    "        \"\"\"\n",
    "        v4.7: Format p-value for display with scientific notation when very small.\n",
    "\n",
    "        This fixes the issue where very small p-values display as 0.000000\n",
    "        \"\"\"\n",
    "        if p_value == 0 or p_value < 1e-300:\n",
    "            return \"< 1e-300\"  # Essentially zero\n",
    "        elif p_value < 1e-100:\n",
    "            return f\"< 1e-100\"\n",
    "        elif p_value < 1e-50:\n",
    "            return f\"< 1e-50\"\n",
    "        elif p_value < 1e-10:\n",
    "            return f\"{p_value:.1e}\"  # Scientific notation\n",
    "        elif p_value < 0.001:\n",
    "            return f\"{p_value:.2e}\"  # Scientific notation\n",
    "        elif p_value < 0.01:\n",
    "            return f\"{p_value:.4f}\"  # 4 decimal places\n",
    "        else:\n",
    "            return f\"{p_value:.4f}\"  # Standard format\n",
    "\n",
    "    @staticmethod\n",
    "    def bootstrap_sharpe_ci(returns: np.ndarray, n_bootstrap: int = 10000,\n",
    "                            confidence: float = 0.95, risk_free_rate: float = 0.0,\n",
    "                            annualization: int = 252) -> Dict[str, float]:\n",
    "        \"\"\"Bootstrap confidence interval for Sharpe ratio.\"\"\"\n",
    "        n = len(returns)\n",
    "        if n < 5:\n",
    "            return {\n",
    "                'sharpe': 0.0, 'ci_lower': 0.0, 'ci_upper': 0.0, 'se_bootstrap': float('inf')\n",
    "            }\n",
    "\n",
    "        sharpe = SharpeStatistics.sharpe_ratio(returns, risk_free_rate, annualization)\n",
    "\n",
    "        bootstrap_sharpes = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            sample = np.random.choice(returns, size=n, replace=True)\n",
    "            boot_sharpe = SharpeStatistics.sharpe_ratio(sample, risk_free_rate, annualization)\n",
    "            bootstrap_sharpes.append(boot_sharpe)\n",
    "\n",
    "        bootstrap_sharpes = np.array(bootstrap_sharpes)\n",
    "\n",
    "        alpha = 1 - confidence\n",
    "        ci_lower = np.percentile(bootstrap_sharpes, 100 * alpha / 2)\n",
    "        ci_upper = np.percentile(bootstrap_sharpes, 100 * (1 - alpha / 2))\n",
    "        se_bootstrap = np.std(bootstrap_sharpes)\n",
    "\n",
    "        return {\n",
    "            'sharpe': sharpe,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'se_bootstrap': se_bootstrap,\n",
    "            'bootstrap_mean': np.mean(bootstrap_sharpes),\n",
    "            'bootstrap_median': np.median(bootstrap_sharpes)\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STRATEGY ENGINE (FIXES #1, #2, #4, #5 - Complete rewrite of core logic)\n",
    "# =============================================================================\n",
    "\n",
    "class ScientificStrategyEngine:\n",
    "    \"\"\"\n",
    "    Main strategy engine with all fixes applied.\n",
    "\n",
    "    v4.4 CRITICAL FIX: PROPER OPTIONS PNL MODEL\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Previous versions used: pnl = position * underlying_return\n",
    "    This is WRONG for options! Options premium selling profits from:\n",
    "    - THETA: Time decay (collect premium daily)\n",
    "    - VEGA: Vol contraction (profit when vol drops)\n",
    "    - GAMMA: Penalty for big moves (squared)\n",
    "\n",
    "    v4.4 uses: pnl = theta_pnl + vega_pnl + gamma_pnl + delta_pnl\n",
    "\n",
    "    This properly models short premium strategies like strangles,\n",
    "    iron condors, credit spreads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ScientificConfig):\n",
    "        self.config = config\n",
    "        self.loader = DataLoader(config)\n",
    "        self.hmm = HMMRegimeDetector(config.hmm_n_states, config.hmm_n_iter)\n",
    "        self.ml = MLSignalGenerator(config)\n",
    "        self.vol_pctl = VolPercentileEngine(config)\n",
    "        self.logger = Logger(config.logging)\n",
    "\n",
    "        # v4.3: Track days since last rebalance\n",
    "        self._days_since_rebalance = 0\n",
    "        self._last_strategy = None\n",
    "\n",
    "    def run(self, df: pd.DataFrame, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Run strategy using walk-forward testing with Greeks-based PnL.\"\"\"\n",
    "\n",
    "        # Reset ML calibration tracking\n",
    "        self.ml.reset_calibration_data()\n",
    "\n",
    "        df = self.loader.add_features(df)\n",
    "\n",
    "        # v4.3: Add smoothed volatility column for ART\n",
    "        vol_window = getattr(self.config, 'vol_smoothing_window', 60)\n",
    "        df['vol_smooth'] = df['ret_1'].rolling(vol_window, min_periods=20).std() * np.sqrt(252)\n",
    "\n",
    "        # v4.4: Calculate vol changes for vega PnL\n",
    "        df['vol_change'] = df['vol_smooth'].diff()\n",
    "\n",
    "        if len(df) < self.config.min_train_size + self.config.test_window:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        results = []\n",
    "        start_idx = self.config.train_window\n",
    "        total_windows = (len(df) - start_idx) // self.config.test_window\n",
    "        window_count = 0\n",
    "\n",
    "        prev_strategy = None\n",
    "        self._days_since_rebalance = 0\n",
    "        self._last_strategy = 'Cash'\n",
    "        global_day_counter = 0\n",
    "\n",
    "        # v4.7 FIX: Running equity tracking for O(n) drawdown calculation\n",
    "        running_equity = 1.0\n",
    "        running_peak = 1.0\n",
    "\n",
    "        while start_idx + self.config.test_window <= len(df):\n",
    "            train_df = df.iloc[start_idx - self.config.train_window:start_idx]\n",
    "            test_df = df.iloc[start_idx:start_idx + self.config.test_window]\n",
    "\n",
    "            # =================================================================\n",
    "            # FIX #1: HMM - Fit on train ONLY, predict on test\n",
    "            # =================================================================\n",
    "            self.hmm.fit(train_df)\n",
    "            test_states, test_probs = self.hmm.predict(test_df)\n",
    "\n",
    "            # =================================================================\n",
    "            # ML - Fit on train, predict on test (v4.3: uses GradientBoosting)\n",
    "            # =================================================================\n",
    "            ml_probs, ml_test_auc = self.ml.fit_predict(train_df, test_df, test_states)\n",
    "\n",
    "            # =================================================================\n",
    "            # Vol Percentile - Uses training distribution\n",
    "            # =================================================================\n",
    "            vol_pctl = self.vol_pctl.calculate_vol_percentile(train_df, test_df)\n",
    "\n",
    "            for i in range(len(test_df)):\n",
    "                row = test_df.iloc[i]\n",
    "                date = test_df.index[i]\n",
    "                global_day_counter += 1\n",
    "\n",
    "                regime_idx = test_states[i] if i < len(test_states) else 1\n",
    "                regime = self.hmm.state_names[regime_idx] if regime_idx < len(self.hmm.state_names) else 'Neutral'\n",
    "                ml_signal = ml_probs[i] if i < len(ml_probs) else 0.5\n",
    "                vp = vol_pctl[i] if i < len(vol_pctl) else 0.5\n",
    "\n",
    "                # v4.6 FIX 2.2: Use pre-computed atr_pct from DataFrame\n",
    "                # (was: atr_14 / close which is already computed in add_features())\n",
    "                atr_pct = row.get('atr_pct', 0.01)\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.8 FIX: EX-ANTE RISK PARAMETERS (no look-ahead!)\n",
    "                # These are based on PAST data known at decision time\n",
    "                # =============================================================\n",
    "                # Yesterday's return (current row's ret_1 is yesterdayâ†’today, already realized)\n",
    "                recent_return = abs(row.get('ret_1', 0))\n",
    "                # Vol-of-vol (uses past rolling window)\n",
    "                vol_of_vol = row.get('vol_of_vol', 0.0)\n",
    "                # Current vol for daily threshold\n",
    "                current_vol_for_gate = row.get('vol_smooth', row.get('vol_20', 0.15))\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.3: TURNOVER CONTROL - Only rebalance every N days\n",
    "                # =============================================================\n",
    "                rebalance_days = getattr(self.config, 'strategy_rebalance_days', 5)\n",
    "                should_rebalance = (global_day_counter % rebalance_days == 0) or (self._last_strategy == 'Cash')\n",
    "\n",
    "                if should_rebalance:\n",
    "                    # v4.8: Use vol-focused strategy selection with ex-ante risk gates\n",
    "                    strategy, base_position = self._select_strategy_v48(\n",
    "                        regime, ml_signal, vp, atr_pct,\n",
    "                        recent_return, vol_of_vol, current_vol_for_gate\n",
    "                    )\n",
    "                    self._last_strategy = strategy\n",
    "                else:\n",
    "                    strategy = self._last_strategy\n",
    "                    _, base_position = self._select_strategy_v48(\n",
    "                        regime, ml_signal, vp, atr_pct,\n",
    "                        recent_return, vol_of_vol, current_vol_for_gate\n",
    "                    )\n",
    "                    if strategy == 'Cash':\n",
    "                        base_position = 0.0\n",
    "\n",
    "                # =============================================================\n",
    "                # FIX #4: Apply strategy-specific leverage\n",
    "                # =============================================================\n",
    "                strategy_leverage = self.config.strategy_leverage.get_leverage(strategy)\n",
    "                position = base_position * strategy_leverage\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.3: CAP POSITION SIZE to reduce risk\n",
    "                # =============================================================\n",
    "                max_pos = getattr(self.config, 'max_position_size', 0.30)\n",
    "                position = np.clip(position, -max_pos, max_pos)\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.7 FIX: DRAWDOWN-BASED POSITION SCALING (O(n) optimized)\n",
    "                # (was O(nÂ²) - recalculated entire history every bar)\n",
    "                # Now uses running_equity and running_peak\n",
    "                # =============================================================\n",
    "                if results:\n",
    "                    # Update running equity with last bar's PnL\n",
    "                    last_pnl = results[-1]['pnl']\n",
    "                    running_equity = running_equity * (1 + last_pnl)\n",
    "                    running_peak = max(running_peak, running_equity)\n",
    "                    current_dd = (running_equity - running_peak) / running_peak if running_peak > 0 else 0.0\n",
    "\n",
    "                    dd_limit_1 = getattr(self.config, 'dd_half_size_threshold', -0.10)\n",
    "                    dd_limit_2 = getattr(self.config, 'dd_flat_threshold', -0.20)\n",
    "\n",
    "                    if current_dd < dd_limit_2:\n",
    "                        # Severe drawdown - go flat\n",
    "                        position = 0.0\n",
    "                        strategy = 'Cash'\n",
    "                    elif current_dd < dd_limit_1:\n",
    "                        # Moderate drawdown - half size\n",
    "                        position *= 0.5\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.4 CRITICAL: Use Greeks-based PnL model\n",
    "                # =============================================================\n",
    "                if i < len(test_df) - 1:\n",
    "                    next_ret = test_df['ret_1'].iloc[i + 1]\n",
    "                    next_vol_change = test_df['vol_change'].iloc[i + 1] if 'vol_change' in test_df.columns else 0\n",
    "                else:\n",
    "                    next_ret = 0\n",
    "                    next_vol_change = 0\n",
    "\n",
    "                # Clean vol change\n",
    "                if np.isnan(next_vol_change):\n",
    "                    next_vol_change = 0\n",
    "\n",
    "                # v4.9: Calculate Greeks-based PnL with asset-specific scaling\n",
    "                greeks_pnl = OptionsGreeksPnLModel.calculate_pnl(\n",
    "                    strategy=strategy,\n",
    "                    position_size=abs(position),\n",
    "                    price_return=next_ret,\n",
    "                    vol_change=next_vol_change,\n",
    "                    days=1.0,\n",
    "                    ticker=ticker  # v4.9: Asset-specific Greek scaling\n",
    "                )\n",
    "\n",
    "                raw_pnl = greeks_pnl['total_pnl']\n",
    "                theta_pnl = greeks_pnl['theta_pnl']\n",
    "                vega_pnl = greeks_pnl['vega_pnl']\n",
    "                gamma_pnl = greeks_pnl['gamma_pnl']\n",
    "                delta_pnl = greeks_pnl['delta_pnl']\n",
    "\n",
    "                # =============================================================\n",
    "                # Calculate current vol (for ART scaling)\n",
    "                # v4.6 FIX 2.1: Use 'is not None' check instead of truthiness\n",
    "                # =============================================================\n",
    "                smooth_vol = test_df['vol_smooth'].iloc[i] if 'vol_smooth' in test_df.columns else None\n",
    "                if smooth_vol is not None and not np.isnan(smooth_vol):\n",
    "                    current_vol = smooth_vol\n",
    "                elif 'vol_20' in test_df.columns:\n",
    "                    current_vol = test_df['vol_20'].iloc[i]\n",
    "                else:\n",
    "                    current_vol = 0.15\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.8 FIX: REMOVED LOOK-AHEAD GAMMA KILL-SWITCH\n",
    "                #\n",
    "                # PROBLEM: Previous versions used gamma_pnl (which depends on\n",
    "                # next_ret) to decide to go to cash. This is LOOK-AHEAD BIAS!\n",
    "                # We were seeing the future loss and then avoiding it.\n",
    "                #\n",
    "                # The ex-ante risk controls are already in _select_strategy_v44:\n",
    "                # - Extreme vol cutoff (98th percentile â†’ smaller position)\n",
    "                # - Vol-of-vol check (high vol-of-vol â†’ avoid)\n",
    "                # - Recent large moves check (based on PAST returns)\n",
    "                # =============================================================\n",
    "                # NO gamma_killed logic here - we take the PnL as it comes\n",
    "\n",
    "                # =============================================================\n",
    "                # FIX 3 (v4.5): SOFTEN ART VOL TARGETING\n",
    "                # When vol spikes â†’ REDUCE positions, don't amplify losses\n",
    "                # =============================================================\n",
    "                ratio = self.config.target_vol / max(current_vol, 0.05)\n",
    "                art_scalar = np.clip(ratio, 0.5, 1.2)\n",
    "                scaled_pnl = raw_pnl * art_scalar\n",
    "\n",
    "                # =============================================================\n",
    "                # v4.7 FIX: Weekend theta/gamma PROPERLY WIRED\n",
    "                # Now uses config.weekend_theta.get_weekend_factor()\n",
    "                # and stores actual factor in weekend_adjustment\n",
    "                # =============================================================\n",
    "                day_of_week = date.dayofweek if hasattr(date, 'dayofweek') else 0\n",
    "                weekend_adjustment = 1.0\n",
    "\n",
    "                if day_of_week == 4:  # Friday\n",
    "                    if strategy not in ['Cash']:\n",
    "                        # v4.7: Actually use weekend_theta config\n",
    "                        dte = self.config.dte_weekly if self.config.use_weekly else self.config.dte_monthly\n",
    "                        weekend_factor = self.config.weekend_theta.get_weekend_factor(dte=dte)\n",
    "                        weekend_adjustment = weekend_factor\n",
    "\n",
    "                        weekend_days = 2.0  # Sat + Sun\n",
    "\n",
    "                        # Add extra theta for weekend (positive = collect premium)\n",
    "                        extra_theta = greeks_pnl['theta_pnl'] * weekend_days\n",
    "\n",
    "                        # v4.6: Also add extra gamma penalty (50% of weekend days)\n",
    "                        extra_gamma = greeks_pnl['gamma_pnl'] * weekend_days * 0.5\n",
    "\n",
    "                        # Apply weekend factor to extra Greeks\n",
    "                        scaled_pnl += (extra_theta + extra_gamma) * weekend_factor\n",
    "\n",
    "                adjusted_pnl = scaled_pnl\n",
    "\n",
    "                # =============================================================\n",
    "                # Transaction costs - v4.6 FIX 2.3: Proportional to actual position change\n",
    "                # (was: max(position_change, 1) which over-penalized small adjustments)\n",
    "                # =============================================================\n",
    "                tx_cost = 0\n",
    "                if strategy != prev_strategy:\n",
    "                    prev_pos = results[-1]['position'] if results else 0\n",
    "                    position_change = abs(position - prev_pos)\n",
    "                    # v4.6: Cost proportional to position_change with no forced minimum\n",
    "                    tx_cost = (self.config.tx_commission + self.config.tx_spread +\n",
    "                              self.config.tx_slippage) * position_change\n",
    "\n",
    "                prev_strategy = strategy\n",
    "\n",
    "                results.append({\n",
    "                    'date': date,\n",
    "                    'close': row['close'],\n",
    "                    'ret_1': row['ret_1'],\n",
    "                    'strategy': strategy,\n",
    "                    'position': position,\n",
    "                    'base_position': base_position,\n",
    "                    'strategy_leverage': strategy_leverage,\n",
    "                    'regime': regime,\n",
    "                    'regime_idx': regime_idx,\n",
    "                    'ml_prob': ml_signal,\n",
    "                    'ml_test_auc': ml_test_auc,\n",
    "                    'vol_percentile': vp,\n",
    "                    'raw_pnl': raw_pnl,\n",
    "                    'theta_pnl': theta_pnl,\n",
    "                    'vega_pnl': vega_pnl,\n",
    "                    'gamma_pnl': gamma_pnl,\n",
    "                    'delta_pnl': delta_pnl,\n",
    "                    'art_scalar': art_scalar,\n",
    "                    'weekend_adjustment': weekend_adjustment,\n",
    "                    'tx_cost': tx_cost,\n",
    "                    'pnl': adjusted_pnl - tx_cost,\n",
    "                    'regime_prob_0': test_probs[i, 0] if test_probs.shape[1] > 0 else 0,\n",
    "                    'regime_prob_1': test_probs[i, 1] if test_probs.shape[1] > 1 else 0,\n",
    "                    'regime_prob_2': test_probs[i, 2] if test_probs.shape[1] > 2 else 0,\n",
    "                    'day_of_week': day_of_week,\n",
    "                    'is_friday': int(day_of_week == 4),\n",
    "                    'atr_pct': atr_pct,\n",
    "                    'vol_smooth': current_vol,\n",
    "                    'vol_change': next_vol_change\n",
    "                })\n",
    "\n",
    "            start_idx += self.config.test_window\n",
    "            window_count += 1\n",
    "\n",
    "            if self.config.logging.show_progress:\n",
    "                self.logger.progress(window_count, total_windows, \"Walk-forward\")\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        if results_df.empty:\n",
    "            return results_df\n",
    "\n",
    "        results_df.set_index('date', inplace=True)\n",
    "        results_df['equity'] = (1 + results_df['pnl']).cumprod() * self.config.account_size\n",
    "        rolling_max = results_df['equity'].cummax()\n",
    "        results_df['drawdown'] = (results_df['equity'] - rolling_max) / rolling_max\n",
    "\n",
    "        # Turnover tracking\n",
    "        results_df['position_change'] = results_df['position'].diff().abs().fillna(0)\n",
    "        results_df['strategy_change'] = (results_df['strategy'] != results_df['strategy'].shift(1)).astype(int)\n",
    "\n",
    "        # Forecast columns for analysis\n",
    "        results_df['forecast'] = (results_df['ml_prob'] * 2 - 1) * results_df['ret_1'].rolling(20).std() * self.config.forecast_horizon\n",
    "        results_df['realized_ret_h'] = results_df['close'].shift(-self.config.forecast_horizon) / results_df['close'] - 1\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def _select_strategy_v44(self, regime: str, ml_signal: float, vol_pctl: float,\n",
    "                              atr_pct: float) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        v4.6 ENHANCED: Strategy selection focused on VOL MEAN REVERSION.\n",
    "\n",
    "        KEY INSIGHT: Don't try to predict direction (ML AUC ~0.50)!\n",
    "        Instead, sell premium when vol is HIGH and collect theta + vega PnL\n",
    "        as vol mean-reverts.\n",
    "\n",
    "        v4.6 ENHANCEMENTS:\n",
    "        - FIX 3.2a: Extreme vol cutoff (98th pctl â†’ reduce/flat)\n",
    "        - FIX 3.2b: ML confidence nudges position size (not direction)\n",
    "\n",
    "        v4.5 RETAINED:\n",
    "        - Vol threshold at 75th percentile\n",
    "        - Focus on delta-neutral strategies\n",
    "        \"\"\"\n",
    "        # v4.5: Use config threshold (default 0.75)\n",
    "        vol_threshold = getattr(self.config, 'vol_percentile_threshold', 0.75)\n",
    "\n",
    "        # Gate 1: Only trade when vol is elevated (premium is rich)\n",
    "        if vol_pctl < vol_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        # Gate 2: Skip extremely quiet markets (no movement = no premium)\n",
    "        atr_threshold = getattr(self.config, 'atr_sideways_threshold', 0.002)\n",
    "        if atr_pct < atr_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        # =============================================================\n",
    "        # v4.6 FIX 3.2a: EXTREME VOL CUTOFF\n",
    "        # Above 98th percentile â†’ either go smaller or flat\n",
    "        # This cuts off worst gamma tails, improving Sortino\n",
    "        # =============================================================\n",
    "        extreme_vol_cutoff = getattr(self.config, 'extreme_vol_cutoff', 0.98)\n",
    "        if vol_pctl >= extreme_vol_cutoff:\n",
    "            # Too crazy - reduce to conservative position or go flat\n",
    "            return 'IronCondor', 0.25  # Very conservative\n",
    "\n",
    "        # Strategy selection based on regime\n",
    "        # ALL strategies are premium-focused, NOT directional betting\n",
    "        if regime == 'Bull':\n",
    "            base_position = 0.5\n",
    "            strategy = 'IronCondor'\n",
    "        elif regime == 'Bear':\n",
    "            base_position = 0.5\n",
    "            strategy = 'IronCondor'\n",
    "        else:\n",
    "            base_position = 0.6\n",
    "            strategy = 'Strangle'\n",
    "\n",
    "        # =============================================================\n",
    "        # v4.6 FIX 3.2b: ML CONFIDENCE SIZE ADJUSTMENT\n",
    "        # Use ML confidence to nudge size (not direction!)\n",
    "        # When ML is very confident, take slightly more exposure\n",
    "        # Cap at +15% to avoid overfit\n",
    "        # =============================================================\n",
    "        ml_confidence = abs(ml_signal - 0.5)  # 0 = unsure, 0.5 = very confident\n",
    "        size_multiplier = 1.0 + min(ml_confidence, 0.15)  # Max +15%\n",
    "        base_position *= size_multiplier\n",
    "\n",
    "        return strategy, base_position\n",
    "\n",
    "    def _select_strategy_v48(self, regime: str, ml_signal: float, vol_pctl: float,\n",
    "                              atr_pct: float, recent_return: float, vol_of_vol: float,\n",
    "                              current_vol: float) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        v4.8 FIXED: Strategy selection with EX-ANTE risk gates only.\n",
    "\n",
    "        CRITICAL FIX: All risk checks use PAST/CURRENT data only!\n",
    "        No look-ahead bias - we don't see future returns.\n",
    "\n",
    "        EX-ANTE RISK GATES:\n",
    "        1. Recent large move gate - if yesterday had big move, reduce exposure\n",
    "        2. Vol-of-vol gate - if vol is unstable, reduce/avoid\n",
    "        3. Extreme vol cutoff - if vol at 98th pctl, reduce\n",
    "        4. ATR gate - if market too quiet, skip\n",
    "        \"\"\"\n",
    "        # Gate 1: Only trade when vol is elevated (premium is rich)\n",
    "        vol_threshold = getattr(self.config, 'vol_percentile_threshold', 0.75)\n",
    "        if vol_pctl < vol_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        # Gate 2: Skip extremely quiet markets\n",
    "        atr_threshold = getattr(self.config, 'atr_sideways_threshold', 0.002)\n",
    "        if atr_pct < atr_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        # =============================================================\n",
    "        # v4.8 EX-ANTE GATE 1: RECENT LARGE MOVE CHECK\n",
    "        # If yesterday had a move > 2x daily vol, reduce exposure today\n",
    "        # This is NOT look-ahead - we're using PAST realized return\n",
    "        # =============================================================\n",
    "        large_move_threshold = getattr(self.config, 'large_move_threshold', 2.0)\n",
    "        daily_vol = current_vol / np.sqrt(252) if current_vol > 0 else 0.01\n",
    "\n",
    "        recent_move_scalar = 1.0\n",
    "        if recent_return > 3.0 * daily_vol:\n",
    "            # Huge move yesterday â†’ go flat today (too risky after big gap)\n",
    "            return 'Cash', 0.0\n",
    "        elif recent_return > large_move_threshold * daily_vol:\n",
    "            # Big move yesterday â†’ reduce exposure today\n",
    "            recent_move_scalar = 0.5\n",
    "\n",
    "        # =============================================================\n",
    "        # v4.8 EX-ANTE GATE 2: VOL-OF-VOL CHECK\n",
    "        # High vol-of-vol = vol is unstable â†’ bad for premium selling\n",
    "        # Only trade when vol is mean-reverting, not expanding\n",
    "        # =============================================================\n",
    "        vol_of_vol_threshold = getattr(self.config, 'vol_of_vol_threshold', 0.15)\n",
    "\n",
    "        vov_scalar = 1.0\n",
    "        if not np.isnan(vol_of_vol) and vol_of_vol > 0:\n",
    "            if vol_of_vol > vol_of_vol_threshold * 1.5:\n",
    "                # Vol very unstable - minimal exposure\n",
    "                vov_scalar = 0.3\n",
    "            elif vol_of_vol > vol_of_vol_threshold:\n",
    "                # Vol is unstable - reduce exposure\n",
    "                vov_scalar = 0.6\n",
    "\n",
    "        # =============================================================\n",
    "        # v4.8 EX-ANTE GATE 3: EXTREME VOL CUTOFF\n",
    "        # Above 98th percentile â†’ go much smaller\n",
    "        # =============================================================\n",
    "        extreme_vol_cutoff = getattr(self.config, 'extreme_vol_cutoff', 0.98)\n",
    "        extreme_scalar = 1.0\n",
    "        if vol_pctl >= extreme_vol_cutoff:\n",
    "            extreme_scalar = 0.4\n",
    "\n",
    "        # Strategy selection based on regime\n",
    "        if regime == 'Bull':\n",
    "            base_position = 0.5\n",
    "            strategy = 'IronCondor'\n",
    "        elif regime == 'Bear':\n",
    "            base_position = 0.5\n",
    "            strategy = 'IronCondor'\n",
    "        else:\n",
    "            base_position = 0.6\n",
    "            strategy = 'Strangle'\n",
    "\n",
    "        # ML confidence size adjustment (retained from v4.6)\n",
    "        ml_confidence = abs(ml_signal - 0.5)\n",
    "        size_multiplier = 1.0 + min(ml_confidence, 0.15)\n",
    "\n",
    "        # Apply all ex-ante scalars\n",
    "        base_position *= size_multiplier * recent_move_scalar * vov_scalar * extreme_scalar\n",
    "\n",
    "        # If position is too small after all gates, go to cash\n",
    "        if base_position < 0.15:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        return strategy, base_position\n",
    "\n",
    "    def _select_strategy_v43(self, regime: str, ml_signal: float, vol_pctl: float,\n",
    "                              atr_pct: float) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        v4.3 strategy selection (kept for comparison).\n",
    "        Uses ML-based directional betting - now deprecated in v4.4.\n",
    "        \"\"\"\n",
    "        vol_threshold = getattr(self.config, 'vol_percentile_threshold', 0.85)\n",
    "        if vol_pctl < vol_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        atr_threshold = getattr(self.config, 'atr_sideways_threshold', 0.005)\n",
    "        is_sideways = atr_pct < atr_threshold\n",
    "\n",
    "        min_prob = getattr(self.config, 'ml_min_probability', 0.55)\n",
    "        strong_prob = min_prob + 0.10\n",
    "\n",
    "        if regime == 'Bull':\n",
    "            if ml_signal > strong_prob and not is_sideways:\n",
    "                return 'BullPutSpread', 0.7\n",
    "            elif ml_signal > min_prob:\n",
    "                return 'IronCondor', 0.4\n",
    "            else:\n",
    "                return 'Cash', 0.0\n",
    "\n",
    "        elif regime == 'Bear':\n",
    "            if ml_signal < (1 - strong_prob) and not is_sideways:\n",
    "                return 'BearCallSpread', -0.7\n",
    "            elif ml_signal < (1 - min_prob):\n",
    "                return 'IronCondor', -0.4\n",
    "            else:\n",
    "                return 'Cash', 0.0\n",
    "\n",
    "        else:\n",
    "            if is_sideways:\n",
    "                return 'Cash', 0.0\n",
    "            elif ml_signal > strong_prob:\n",
    "                return 'ShortPut', 0.3\n",
    "            elif ml_signal < (1 - strong_prob):\n",
    "                return 'ShortCall', -0.3\n",
    "            elif abs(ml_signal - 0.5) < 0.05:\n",
    "                return 'Strangle', 0.2\n",
    "            else:\n",
    "                return 'Cash', 0.0\n",
    "\n",
    "        return 'Cash', 0.0\n",
    "\n",
    "    def _select_strategy(self, regime: str, ml_signal: float, vol_pctl: float) -> Tuple[str, float]:\n",
    "        \"\"\"Legacy strategy selection (kept for compatibility).\"\"\"\n",
    "        if vol_pctl < self.config.vol_percentile_threshold:\n",
    "            return 'Cash', 0.0\n",
    "\n",
    "        if regime == 'Bull':\n",
    "            if ml_signal > 0.6:\n",
    "                return 'BullPutSpread', 1.0\n",
    "            elif ml_signal > 0.4:\n",
    "                return 'IronCondor', 0.5\n",
    "            else:\n",
    "                return 'Cash', 0.0\n",
    "        elif regime == 'Bear':\n",
    "            if ml_signal < 0.4:\n",
    "                return 'BearCallSpread', -1.0\n",
    "            elif ml_signal < 0.6:\n",
    "                return 'IronCondor', -0.5\n",
    "            else:\n",
    "                return 'Cash', 0.0\n",
    "        else:\n",
    "            if ml_signal > 0.55:\n",
    "                return 'ShortPut', 0.5\n",
    "            elif ml_signal < 0.45:\n",
    "                return 'ShortCall', -0.5\n",
    "            else:\n",
    "                return 'Strangle', 0.3\n",
    "\n",
    "        return 'Cash', 0.0\n",
    "\n",
    "    def get_ml_calibration_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Get ML predictions and outcomes for calibration analysis.\"\"\"\n",
    "        return self.ml.get_calibration_data()\n",
    "\n",
    "    def get_ml_global_oos_auc(self) -> float:\n",
    "        \"\"\"Get overall OOS AUC.\"\"\"\n",
    "        return self.ml.get_global_oos_auc()\n",
    "\n",
    "    def get_ml_mean_window_auc(self) -> float:\n",
    "        \"\"\"Get mean per-window test AUC.\"\"\"\n",
    "        return self.ml.get_mean_window_auc()\n",
    "\n",
    "    def get_turnover_metrics(self, results_df: pd.DataFrame = None) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate turnover metrics from results.\n",
    "\n",
    "        v4.0 NEW: Track position changes and strategy switches.\n",
    "        \"\"\"\n",
    "        if results_df is None:\n",
    "            # Try to get from last run if stored\n",
    "            return {\n",
    "                'daily_turnover': 0.0,\n",
    "                'annual_turnover': 0.0,\n",
    "                'strategy_changes': 0,\n",
    "                'avg_holding_period': 0.0\n",
    "            }\n",
    "\n",
    "        if 'position_change' not in results_df.columns:\n",
    "            return {\n",
    "                'daily_turnover': 0.0,\n",
    "                'annual_turnover': 0.0,\n",
    "                'strategy_changes': 0,\n",
    "                'avg_holding_period': 0.0\n",
    "            }\n",
    "\n",
    "        daily_turnover = results_df['position_change'].mean()\n",
    "        strategy_changes = results_df['strategy_change'].sum() if 'strategy_change' in results_df.columns else 0\n",
    "\n",
    "        return {\n",
    "            'daily_turnover': daily_turnover,\n",
    "            'annual_turnover': daily_turnover * 252 * 100,\n",
    "            'strategy_changes': int(strategy_changes),\n",
    "            'avg_holding_period': len(results_df) / max(strategy_changes, 1)\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS CALCULATOR (Enhanced with new metrics)\n",
    "# =============================================================================\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics.\n",
    "\n",
    "    VaR/ES SIGN CONVENTION NOTE:\n",
    "    - VaR 95% is the 5th percentile of returns (a negative number for most strategies)\n",
    "    - ES 95% is the mean of returns below VaR (also negative)\n",
    "    - VaR Loss / ES Loss are the absolute values (positive loss numbers)\n",
    "\n",
    "    Example: If VaR 95% = -0.023, that means \"5% of days have returns worse than -2.3%\"\n",
    "             VaR Loss 95% = 0.023 (same info as positive loss)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_all(df: pd.DataFrame, ml_engine: MLSignalGenerator = None) -> Dict[str, float]:\n",
    "        \"\"\"Calculate all performance metrics.\"\"\"\n",
    "        metrics = {}\n",
    "        if 'pnl' not in df.columns or len(df) == 0:\n",
    "            return metrics\n",
    "\n",
    "        returns = df['pnl']\n",
    "        equity = df['equity'] if 'equity' in df.columns else (1 + returns).cumprod()\n",
    "\n",
    "        # Basic returns\n",
    "        total_return = (equity.iloc[-1] / equity.iloc[0]) - 1\n",
    "        metrics['Total Return'] = total_return\n",
    "\n",
    "        n_years = len(df) / 252\n",
    "        metrics['CAGR'] = (equity.iloc[-1] / equity.iloc[0]) ** (1 / max(n_years, 0.01)) - 1 if equity.iloc[0] > 0 else 0\n",
    "\n",
    "        # Risk metrics\n",
    "        ann_vol = returns.std() * np.sqrt(252)\n",
    "        metrics['Realized Vol'] = ann_vol\n",
    "        metrics['Sharpe'] = (returns.mean() * 252) / ann_vol if ann_vol > 0 else 0\n",
    "\n",
    "        downside = returns[returns < 0]\n",
    "        downside_vol = downside.std() * np.sqrt(252) if len(downside) > 2 else ann_vol\n",
    "        metrics['Sortino'] = (returns.mean() * 252) / downside_vol if downside_vol > 0 else 0\n",
    "\n",
    "        rolling_max = equity.cummax()\n",
    "        drawdown = (equity - rolling_max) / rolling_max\n",
    "        metrics['Max Drawdown'] = drawdown.min()\n",
    "        metrics['Calmar'] = metrics['CAGR'] / abs(metrics['Max Drawdown']) if metrics['Max Drawdown'] != 0 else 0\n",
    "\n",
    "        winning_days = (returns > 0).sum()\n",
    "        total_days = (returns != 0).sum()\n",
    "        metrics['Win Rate'] = winning_days / total_days if total_days > 0 else 0\n",
    "\n",
    "        # VaR/ES: Returns at tail (negative numbers for losses)\n",
    "        # Sign convention: negative = loss, matches return sign\n",
    "        metrics['VaR 95%'] = returns.quantile(0.05)\n",
    "        tail_returns = returns[returns <= metrics['VaR 95%']]\n",
    "        metrics['ES 95%'] = tail_returns.mean() if len(tail_returns) > 0 else metrics['VaR 95%']\n",
    "\n",
    "        # VaR/ES Loss: Absolute values (positive numbers for losses)\n",
    "        # Convention: many risk dashboards prefer positive loss numbers\n",
    "        metrics['VaR Loss 95%'] = abs(metrics['VaR 95%'])\n",
    "        metrics['ES Loss 95%'] = abs(metrics['ES 95%'])\n",
    "\n",
    "        metrics['Skewness'] = returns.skew()\n",
    "        metrics['Kurtosis'] = returns.kurtosis()\n",
    "\n",
    "        gains = returns[returns > 0].sum()\n",
    "        losses = -returns[returns < 0].sum()\n",
    "        metrics['Omega'] = gains / losses if losses > 0 else float('inf')\n",
    "        metrics['Profit Factor'] = gains / losses if losses > 0 else float('inf')\n",
    "\n",
    "        # Transaction costs\n",
    "        if 'tx_cost' in df.columns:\n",
    "            metrics['Total TX Cost'] = df['tx_cost'].sum()\n",
    "            metrics['Num Trades'] = df['strategy_change'].sum() if 'strategy_change' in df.columns else 0\n",
    "\n",
    "        # Turnover metrics (NEW)\n",
    "        if 'position_change' in df.columns:\n",
    "            metrics['Daily Turnover %'] = df['position_change'].mean() * 100\n",
    "            metrics['Annual Turnover %'] = df['position_change'].mean() * 252 * 100\n",
    "\n",
    "        # ML metrics - FIX #3: Use OOS AUC\n",
    "        if ml_engine is not None:\n",
    "            # Handle both MLSignalGenerator and ScientificStrategyEngine\n",
    "            if hasattr(ml_engine, 'ml'):\n",
    "                # It's a ScientificStrategyEngine - use its ml attribute\n",
    "                metrics['ML OOS AUC (Global)'] = ml_engine.ml.get_global_oos_auc()\n",
    "                metrics['ML OOS AUC (Mean Window)'] = ml_engine.ml.get_mean_window_auc()\n",
    "            elif hasattr(ml_engine, 'get_global_oos_auc'):\n",
    "                # It's an MLSignalGenerator\n",
    "                metrics['ML OOS AUC (Global)'] = ml_engine.get_global_oos_auc()\n",
    "                metrics['ML OOS AUC (Mean Window)'] = ml_engine.get_mean_window_auc()\n",
    "        elif 'ml_test_auc' in df.columns:\n",
    "            metrics['ML OOS AUC (Last)'] = df['ml_test_auc'].iloc[-1]\n",
    "\n",
    "        metrics['Vol Target Hit'] = 0.10 <= ann_vol <= 0.14\n",
    "\n",
    "        # Weekend theta impact (NEW)\n",
    "        if 'weekend_adjustment' in df.columns:\n",
    "            friday_mask = df['is_friday'] == 1 if 'is_friday' in df.columns else pd.Series([False] * len(df))\n",
    "            if friday_mask.any():\n",
    "                metrics['Avg Weekend Theta Adj'] = df.loc[friday_mask, 'weekend_adjustment'].mean()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NEW VISUALIZATION: ML LIFT CURVE / RANK BUCKET PLOT\n",
    "# =============================================================================\n",
    "\n",
    "def plot_ml_lift_curve(predictions: np.ndarray, outcomes: np.ndarray, returns: np.ndarray,\n",
    "                        ticker: str = \"\", n_buckets: int = 10,\n",
    "                        pdf: Optional[PdfPages] = None) -> Optional[plt.Figure]:\n",
    "    \"\"\"\n",
    "    Plot ML lift curve - average return by prediction quintile.\n",
    "\n",
    "    Shows whether higher ML probability leads to higher returns.\n",
    "    \"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    if len(predictions) < 50:\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    # Align arrays\n",
    "    n = min(len(predictions), len(outcomes), len(returns))\n",
    "    predictions = predictions[:n]\n",
    "    outcomes = outcomes[:n]\n",
    "    returns = returns[:n]\n",
    "\n",
    "    # Create buckets based on predicted probability\n",
    "    bucket_edges = np.percentile(predictions, np.linspace(0, 100, n_buckets + 1))\n",
    "    bucket_edges[-1] += 0.001  # Ensure max is included\n",
    "    bucket_indices = np.digitize(predictions, bucket_edges[1:])\n",
    "\n",
    "    bucket_data = []\n",
    "    for i in range(n_buckets):\n",
    "        mask = bucket_indices == i\n",
    "        if mask.sum() > 0:\n",
    "            bucket_data.append({\n",
    "                'bucket': i + 1,\n",
    "                'mean_prob': predictions[mask].mean(),\n",
    "                'mean_return': returns[mask].mean() * 10000,  # bps\n",
    "                'hit_rate': outcomes[mask].mean(),\n",
    "                'count': mask.sum()\n",
    "            })\n",
    "\n",
    "    bucket_df = pd.DataFrame(bucket_data)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7), facecolor=DarkTheme.BACKGROUND)\n",
    "\n",
    "    # Left: Return by bucket\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    colors = [DarkTheme.GREEN if r > 0 else DarkTheme.RED for r in bucket_df['mean_return']]\n",
    "    ax1.bar(bucket_df['bucket'], bucket_df['mean_return'], color=colors,\n",
    "            alpha=0.8, edgecolor='white')\n",
    "    ax1.axhline(0, color=DarkTheme.TEXT_DIM, linestyle='--')\n",
    "    ax1.set_xlabel('ML Probability Decile (1=Lowest, 10=Highest)', color=DarkTheme.TEXT)\n",
    "    ax1.set_ylabel('Mean Next-Day Return (bps)', color=DarkTheme.TEXT)\n",
    "    ax1.set_title(f'{ticker} â€“ ML Lift Curve: Return by Prediction Bucket',\n",
    "                  fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax1.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    # Right: Hit rate by bucket\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    ax2.bar(bucket_df['bucket'], bucket_df['hit_rate'] * 100,\n",
    "            color=DarkTheme.BLUE, alpha=0.8, edgecolor='white')\n",
    "    ax2.axhline(50, color=DarkTheme.GOLD, linestyle='--', label='Random (50%)')\n",
    "    ax2.set_xlabel('ML Probability Decile', color=DarkTheme.TEXT)\n",
    "    ax2.set_ylabel('Actual Up-Day Rate (%)', color=DarkTheme.TEXT)\n",
    "    ax2.set_title(f'{ticker} â€“ Hit Rate by Prediction Bucket',\n",
    "                  fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax2.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax2.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "        plt.close(fig)\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    reset_light_theme()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NEW VISUALIZATION: TURNOVER & EXPOSURE PLOTS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_turnover_exposure(df: pd.DataFrame, ticker: str = \"\",\n",
    "                            pdf: Optional[PdfPages] = None) -> Optional[plt.Figure]:\n",
    "    \"\"\"Plot turnover and position exposure time series.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    if len(df) < 20:\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10), facecolor=DarkTheme.BACKGROUND)\n",
    "\n",
    "    # 1. Position exposure over time\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    if 'position' in df.columns:\n",
    "        ax1.fill_between(df.index, 0, df['position'], where=df['position'] > 0,\n",
    "                        color=DarkTheme.GREEN, alpha=0.5, label='Long')\n",
    "        ax1.fill_between(df.index, 0, df['position'], where=df['position'] < 0,\n",
    "                        color=DarkTheme.RED, alpha=0.5, label='Short')\n",
    "        ax1.plot(df.index, df['position'], color=DarkTheme.BLUE, linewidth=1)\n",
    "\n",
    "    ax1.axhline(0, color=DarkTheme.TEXT_DIM, linestyle='--')\n",
    "    ax1.set_title('Net Position Exposure Over Time', fontsize=12, color=DarkTheme.TEXT)\n",
    "    ax1.set_ylabel('Position', color=DarkTheme.TEXT)\n",
    "    ax1.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax1.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    # 2. Gross exposure (absolute position)\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    if 'position' in df.columns:\n",
    "        gross_exp = df['position'].abs()\n",
    "        ax2.fill_between(df.index, 0, gross_exp, color=DarkTheme.ORANGE, alpha=0.5)\n",
    "        ax2.plot(df.index, gross_exp, color=DarkTheme.ORANGE, linewidth=1)\n",
    "\n",
    "    ax2.set_title('Gross Exposure Over Time', fontsize=12, color=DarkTheme.TEXT)\n",
    "    ax2.set_ylabel('|Position|', color=DarkTheme.TEXT)\n",
    "    ax2.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    # 3. Daily turnover\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    if 'position_change' in df.columns:\n",
    "        turnover = df['position_change'] * 100\n",
    "        ax3.bar(df.index, turnover, color=DarkTheme.CYAN, alpha=0.7, width=1)\n",
    "        ax3.axhline(turnover.mean(), color=DarkTheme.GOLD, linestyle='--',\n",
    "                   label=f'Mean: {turnover.mean():.1f}%')\n",
    "\n",
    "    ax3.set_title('Daily Turnover', fontsize=12, color=DarkTheme.TEXT)\n",
    "    ax3.set_ylabel('Turnover (%)', color=DarkTheme.TEXT)\n",
    "    ax3.legend(loc='upper right', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax3.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    # 4. Strategy allocation over time (stacked)\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    if 'strategy' in df.columns:\n",
    "        strategies = df['strategy'].unique()\n",
    "        strategy_colors = {\n",
    "            'Cash': DarkTheme.TEXT_DIM,\n",
    "            'BullPutSpread': DarkTheme.GREEN,\n",
    "            'BearCallSpread': DarkTheme.RED,\n",
    "            'IronCondor': DarkTheme.PURPLE,\n",
    "            'ShortPut': DarkTheme.CYAN,\n",
    "            'ShortCall': DarkTheme.ORANGE,\n",
    "            'Strangle': DarkTheme.PINK\n",
    "        }\n",
    "\n",
    "        # Create running count for each strategy\n",
    "        for strat in strategies:\n",
    "            if strat in strategy_colors:\n",
    "                mask = df['strategy'] == strat\n",
    "                ax4.fill_between(df.index, 0, mask.astype(int) * 0.5,\n",
    "                               alpha=0.5, color=strategy_colors[strat], label=strat)\n",
    "\n",
    "    ax4.set_title('Strategy Allocation Over Time', fontsize=12, color=DarkTheme.TEXT)\n",
    "    ax4.set_ylabel('Active', color=DarkTheme.TEXT)\n",
    "    ax4.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT, fontsize=8, ncol=2)\n",
    "    ax4.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.suptitle(f'{ticker} â€“ Turnover & Exposure Analysis', fontsize=14,\n",
    "                fontweight='bold', color=DarkTheme.TEXT)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "        plt.close(fig)\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    reset_light_theme()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NEW VISUALIZATION: CONFUSION MATRIX BY REGIME\n",
    "# =============================================================================\n",
    "\n",
    "def plot_confusion_by_regime(df: pd.DataFrame, predictions: np.ndarray,\n",
    "                              outcomes: np.ndarray, ticker: str = \"\",\n",
    "                              pdf: Optional[PdfPages] = None) -> Optional[plt.Figure]:\n",
    "    \"\"\"Plot confusion matrix analysis by regime.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    if len(predictions) < 50 or 'regime' not in df.columns:\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    # Align\n",
    "    n = min(len(predictions), len(outcomes), len(df))\n",
    "    predictions = predictions[:n]\n",
    "    outcomes = outcomes[:n]\n",
    "    regimes = df['regime'].iloc[:n].values\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), facecolor=DarkTheme.BACKGROUND)\n",
    "\n",
    "    regime_names = ['Bull', 'Neutral', 'Bear']\n",
    "\n",
    "    for idx, regime_name in enumerate(regime_names):\n",
    "        ax = axes[idx]\n",
    "        ax.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "        mask = regimes == regime_name\n",
    "        if mask.sum() < 10:\n",
    "            ax.text(0.5, 0.5, f'Insufficient data\\n({mask.sum()} samples)',\n",
    "                   ha='center', va='center', fontsize=12, color=DarkTheme.TEXT)\n",
    "            ax.set_title(f'{regime_name} Regime', fontsize=12, color=DarkTheme.TEXT)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        regime_preds = predictions[mask]\n",
    "        regime_outcomes = outcomes[mask]\n",
    "\n",
    "        # Discretize predictions at 0.5\n",
    "        pred_up = regime_preds > 0.5\n",
    "        actual_up = regime_outcomes == 1\n",
    "\n",
    "        # Confusion matrix\n",
    "        TP = (pred_up & actual_up).sum()\n",
    "        TN = (~pred_up & ~actual_up).sum()\n",
    "        FP = (pred_up & ~actual_up).sum()\n",
    "        FN = (~pred_up & actual_up).sum()\n",
    "\n",
    "        cm = np.array([[TN, FP], [FN, TP]])\n",
    "\n",
    "        # Plot as heatmap\n",
    "        im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "\n",
    "        # Add text annotations\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                color = 'white' if cm[i, j] > cm.max() / 2 else DarkTheme.TEXT\n",
    "                ax.text(j, i, f'{cm[i, j]}\\n({cm[i, j] / cm.sum() * 100:.1f}%)',\n",
    "                       ha='center', va='center', fontsize=11, color=color)\n",
    "\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_yticks([0, 1])\n",
    "        ax.set_xticklabels(['Pred Down', 'Pred Up'], color=DarkTheme.TEXT)\n",
    "        ax.set_yticklabels(['Actual Down', 'Actual Up'], color=DarkTheme.TEXT)\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "        ax.set_title(f'{regime_name} Regime (n={mask.sum()})\\nAcc: {accuracy:.1%} | Prec: {precision:.1%} | Rec: {recall:.1%}',\n",
    "                    fontsize=12, color=DarkTheme.TEXT)\n",
    "\n",
    "    plt.suptitle(f'{ticker} â€“ ML Confusion Matrix by Regime', fontsize=14,\n",
    "                fontweight='bold', color=DarkTheme.TEXT)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "        plt.close(fig)\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    reset_light_theme()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PRESERVED VISUALIZATIONS FROM v3 (reliability diagram, sharpe significance)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_reliability_diagram(predictions: np.ndarray, outcomes: np.ndarray,\n",
    "                              n_bins: int = 10, ticker: str = \"\",\n",
    "                              pdf: Optional[PdfPages] = None) -> Optional[plt.Figure]:\n",
    "    \"\"\"Plot reliability diagram (calibration curve) as in ISL p. 455.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    if len(predictions) < 50:\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    mean_pred, frac_pos, counts = CalibrationMetrics.compute_calibration_curve(\n",
    "        predictions, outcomes, n_bins\n",
    "    )\n",
    "\n",
    "    ece = CalibrationMetrics.expected_calibration_error(predictions, outcomes, n_bins)\n",
    "    mce = CalibrationMetrics.maximum_calibration_error(predictions, outcomes, n_bins)\n",
    "    brier = CalibrationMetrics.brier_score(predictions, outcomes)\n",
    "    bss = CalibrationMetrics.brier_skill_score(predictions, outcomes)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7), facecolor=DarkTheme.BACKGROUND)\n",
    "\n",
    "    # Left: Reliability Diagram\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], '--', color=DarkTheme.TEXT_DIM, linewidth=2,\n",
    "             label='Perfect Calibration', alpha=0.8)\n",
    "\n",
    "    valid_mask = ~np.isnan(mean_pred) & ~np.isnan(frac_pos)\n",
    "    if valid_mask.sum() > 0:\n",
    "        x = mean_pred[valid_mask]\n",
    "        y = frac_pos[valid_mask]\n",
    "        n = counts[valid_mask]\n",
    "\n",
    "        sizes = (n / n.max()) * 300 + 50\n",
    "        ax1.scatter(x, y, s=sizes, c=DarkTheme.BLUE, alpha=0.8,\n",
    "                   edgecolors='white', linewidth=1, zorder=5)\n",
    "\n",
    "        sorted_idx = np.argsort(x)\n",
    "        ax1.plot(x[sorted_idx], y[sorted_idx], '-', color=DarkTheme.BLUE,\n",
    "                linewidth=2, alpha=0.8, label='Model Calibration')\n",
    "\n",
    "    ax1.set_xlim([0, 1])\n",
    "    ax1.set_ylim([0, 1])\n",
    "    ax1.set_xlabel('Mean Predicted Probability', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax1.set_ylabel('Fraction of Positives', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax1.set_title(f'{ticker} â€“ Reliability Diagram (ISL Fig 4.18)',\n",
    "                  fontsize=14, color=DarkTheme.TEXT, fontweight='bold')\n",
    "    ax1.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax1.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    metrics_text = (f'ECE: {ece:.4f}\\n'\n",
    "                   f'MCE: {mce:.4f}\\n'\n",
    "                   f'Brier: {brier:.4f}\\n'\n",
    "                   f'BSS: {bss:.4f}')\n",
    "    ax1.text(0.95, 0.05, metrics_text, transform=ax1.transAxes, fontsize=11,\n",
    "             verticalalignment='bottom', horizontalalignment='right',\n",
    "             color=DarkTheme.TEXT,\n",
    "             bbox=dict(boxstyle='round', facecolor=DarkTheme.PANEL,\n",
    "                      edgecolor=DarkTheme.GRID, alpha=0.9))\n",
    "\n",
    "    # Right: Histogram\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    pred_pos = predictions[outcomes == 1]\n",
    "    pred_neg = predictions[outcomes == 0]\n",
    "\n",
    "    bins = np.linspace(0, 1, 21)\n",
    "    ax2.hist(pred_neg, bins=bins, alpha=0.7, color=DarkTheme.RED,\n",
    "             label=f'Outcome=0 (n={len(pred_neg)})', edgecolor='white', linewidth=0.5)\n",
    "    ax2.hist(pred_pos, bins=bins, alpha=0.7, color=DarkTheme.GREEN,\n",
    "             label=f'Outcome=1 (n={len(pred_pos)})', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "    ax2.set_xlabel('Predicted Probability', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax2.set_ylabel('Count', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax2.set_title(f'{ticker} â€“ Prediction Distribution by Outcome',\n",
    "                  fontsize=14, color=DarkTheme.TEXT, fontweight='bold')\n",
    "    ax2.legend(loc='upper center', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax2.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "        plt.close(fig)\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    reset_light_theme()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_sharpe_significance(returns: np.ndarray, ticker: str = \"\",\n",
    "                              pdf: Optional[PdfPages] = None,\n",
    "                              precomputed_ttest: Dict = None,\n",
    "                              precomputed_bootstrap: Dict = None,\n",
    "                              n_bootstrap: int = 2000) -> Optional[plt.Figure]:\n",
    "    \"\"\"\n",
    "    Plot Sharpe ratio with statistical significance analysis.\n",
    "\n",
    "    FIX 2.5: Now accepts precomputed results to avoid double bootstrapping.\n",
    "    Reduced default n_bootstrap from 5000 to 2000 for speed.\n",
    "\n",
    "    Args:\n",
    "        returns: Array of returns\n",
    "        ticker: Asset ticker for title\n",
    "        pdf: Optional PDF to save to\n",
    "        precomputed_ttest: Pre-computed t-test results (optional)\n",
    "        precomputed_bootstrap: Pre-computed bootstrap results (optional)\n",
    "        n_bootstrap: Number of bootstrap samples if computing fresh\n",
    "    \"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    if len(returns) < 30:\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    # Use precomputed results if available, else compute\n",
    "    if precomputed_ttest is not None:\n",
    "        ttest_results = precomputed_ttest\n",
    "    else:\n",
    "        ttest_results = SharpeStatistics.sharpe_ttest(returns)\n",
    "\n",
    "    if precomputed_bootstrap is not None:\n",
    "        bootstrap_results = precomputed_bootstrap\n",
    "        # Still need the distribution for plotting - but with fewer samples\n",
    "        n = len(returns)\n",
    "        bootstrap_sharpes = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            sample = np.random.choice(returns, size=n, replace=True)\n",
    "            boot_sharpe = SharpeStatistics.sharpe_ratio(sample)\n",
    "            bootstrap_sharpes.append(boot_sharpe)\n",
    "        bootstrap_sharpes = np.array(bootstrap_sharpes)\n",
    "    else:\n",
    "        # Compute bootstrap with distribution in one pass\n",
    "        n = len(returns)\n",
    "        bootstrap_sharpes = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            sample = np.random.choice(returns, size=n, replace=True)\n",
    "            boot_sharpe = SharpeStatistics.sharpe_ratio(sample)\n",
    "            bootstrap_sharpes.append(boot_sharpe)\n",
    "        bootstrap_sharpes = np.array(bootstrap_sharpes)\n",
    "\n",
    "        # Derive CI and stats from distribution\n",
    "        bootstrap_results = {\n",
    "            'sharpe': SharpeStatistics.sharpe_ratio(returns),\n",
    "            'ci_lower': np.percentile(bootstrap_sharpes, 2.5),\n",
    "            'ci_upper': np.percentile(bootstrap_sharpes, 97.5),\n",
    "            'se_bootstrap': np.std(bootstrap_sharpes),\n",
    "            'bootstrap_mean': np.mean(bootstrap_sharpes),\n",
    "            'bootstrap_median': np.median(bootstrap_sharpes)\n",
    "        }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7), facecolor=DarkTheme.BACKGROUND)\n",
    "\n",
    "    # Left: Bootstrap distribution\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    ax1.hist(bootstrap_sharpes, bins=50, density=True, alpha=0.7,\n",
    "             color=DarkTheme.HISTOGRAM, edgecolor='white', linewidth=0.5)\n",
    "\n",
    "    sharpe = ttest_results['sharpe']\n",
    "    ci_lower = bootstrap_results['ci_lower']\n",
    "    ci_upper = bootstrap_results['ci_upper']\n",
    "\n",
    "    ax1.axvline(sharpe, color=DarkTheme.BLUE, linewidth=3,\n",
    "                label=f'Sharpe = {sharpe:.4f}')\n",
    "    ax1.axvline(0, color=DarkTheme.RED, linewidth=2, linestyle='--',\n",
    "                label='Hâ‚€: Sharpe = 0')\n",
    "    ax1.axvline(ci_lower, color=DarkTheme.GREEN, linewidth=2, linestyle=':',\n",
    "                label=f'95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]')\n",
    "    ax1.axvline(ci_upper, color=DarkTheme.GREEN, linewidth=2, linestyle=':')\n",
    "\n",
    "    ax1.axvspan(ci_lower, ci_upper, alpha=0.2, color=DarkTheme.GREEN)\n",
    "\n",
    "    ax1.set_xlabel('Sharpe Ratio', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax1.set_ylabel('Density', color=DarkTheme.TEXT, fontsize=12)\n",
    "    ax1.set_title(f'{ticker} â€“ Bootstrap Distribution of Sharpe Ratio',\n",
    "                  fontsize=14, color=DarkTheme.TEXT, fontweight='bold')\n",
    "    ax1.legend(loc='upper right', facecolor=DarkTheme.PANEL,\n",
    "               edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT, fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    # Right: Summary\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_facecolor(DarkTheme.PANEL)\n",
    "    ax2.axis('off')\n",
    "\n",
    "    sig_5 = \"âœ“ Yes\" if ttest_results['significant_5pct'] else \"âœ— No\"\n",
    "    sig_1 = \"âœ“ Yes\" if ttest_results['significant_1pct'] else \"âœ— No\"\n",
    "\n",
    "    summary_text = f\"\"\"\n",
    "    SHARPE RATIO STATISTICAL SIGNIFICANCE TEST\n",
    "    {'â”€' * 50}\n",
    "\n",
    "    Sample Size (n):           {len(returns):,} days\n",
    "\n",
    "    Point Estimate:\n",
    "      Sharpe Ratio:            {sharpe:.4f}\n",
    "      Standard Error:          {ttest_results['se']:.4f}\n",
    "\n",
    "    T-Test (Hâ‚€: Sharpe = 0):\n",
    "      t-statistic:             {ttest_results['t_stat']:.4f}\n",
    "      p-value:                 {ttest_results['p_value']:.6f}\n",
    "      Degrees of freedom:      {ttest_results['df']}\n",
    "\n",
    "    Significance:\n",
    "      At Î± = 0.05:             {sig_5}\n",
    "      At Î± = 0.01:             {sig_1}\n",
    "\n",
    "    Confidence Intervals:\n",
    "      Analytical 95% CI:       [{ttest_results['ci_95_lower']:.4f}, {ttest_results['ci_95_upper']:.4f}]\n",
    "      Bootstrap 95% CI:        [{ci_lower:.4f}, {ci_upper:.4f}]\n",
    "\n",
    "    Bootstrap Statistics:\n",
    "      Mean:                    {bootstrap_results['bootstrap_mean']:.4f}\n",
    "      Median:                  {bootstrap_results['bootstrap_median']:.4f}\n",
    "      Std Error:               {bootstrap_results['se_bootstrap']:.4f}\n",
    "    \"\"\"\n",
    "\n",
    "    ax2.text(0.05, 0.95, summary_text, transform=ax2.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             color=DarkTheme.TEXT,\n",
    "             bbox=dict(boxstyle='round', facecolor=DarkTheme.PANEL,\n",
    "                      edgecolor=DarkTheme.GRID, alpha=0.9))\n",
    "\n",
    "    ax2.set_title(f'{ticker} â€“ Sharpe Ratio T-Test Results',\n",
    "                  fontsize=14, color=DarkTheme.TEXT, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "        plt.close(fig)\n",
    "        reset_light_theme()\n",
    "        return None\n",
    "\n",
    "    reset_light_theme()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ADDITIONAL STANDARD PLOTS (Preserved from v3)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_monthly_returns_line(ticker: str, df: pd.DataFrame, pdf: PdfPages):\n",
    "    \"\"\"Monthly returns as LINE plot.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    monthly_strategy = df['pnl'].resample('M').sum() * 100\n",
    "    monthly_buyhold = df['ret_1'].resample('M').sum() * 100\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 6), facecolor=DarkTheme.BACKGROUND)\n",
    "    ax.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    ax.plot(monthly_strategy.index, monthly_strategy.values,\n",
    "            color=DarkTheme.BLUE, linewidth=2, marker='o', markersize=4, label='Strategy')\n",
    "    ax.plot(monthly_buyhold.index, monthly_buyhold.values,\n",
    "            color=DarkTheme.ORANGE, linewidth=2, marker='s', markersize=4, label='Buy & Hold')\n",
    "\n",
    "    ax.axhline(0, color=DarkTheme.TEXT_DIM, linewidth=0.8, linestyle='--', alpha=0.5)\n",
    "    ax.set_title(f'{ticker} â€“ Monthly Returns: Strategy vs Buy & Hold',\n",
    "                fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax.set_xlabel('Date', color=DarkTheme.TEXT)\n",
    "    ax.set_ylabel('Monthly Return (%)', color=DarkTheme.TEXT)\n",
    "    ax.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "             edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    reset_light_theme()\n",
    "\n",
    "\n",
    "def plot_price_with_trade_entries(ticker: str, df: pd.DataFrame, pdf: PdfPages):\n",
    "    \"\"\"Price with trades using ACTUAL prices.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 6), facecolor=DarkTheme.BACKGROUND)\n",
    "    ax.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    prices = df['close']\n",
    "    ax.plot(df.index, prices, color=DarkTheme.BLUE, linewidth=1.5, label='Price')\n",
    "\n",
    "    if 'position' in df.columns:\n",
    "        pos_change = df['position'].diff().fillna(0)\n",
    "        long_mask = pos_change > 0\n",
    "        short_mask = pos_change < 0\n",
    "\n",
    "        ax.scatter(df.index[long_mask], prices[long_mask], marker='^', s=100,\n",
    "                   c=DarkTheme.GREEN, label=f'Long Entry ({long_mask.sum()})',\n",
    "                   zorder=5, edgecolors='white', linewidth=0.5)\n",
    "        ax.scatter(df.index[short_mask], prices[short_mask], marker='v', s=100,\n",
    "                   c=DarkTheme.ORANGE, label=f'Short Entry ({short_mask.sum()})',\n",
    "                   zorder=5, edgecolors='white', linewidth=0.5)\n",
    "\n",
    "    ax.set_title(f'{ticker} â€“ Price with Trade Entries', fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax.set_xlabel('Date', color=DarkTheme.TEXT)\n",
    "    ax.set_ylabel('Price', color=DarkTheme.TEXT)\n",
    "    ax.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "             edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    reset_light_theme()\n",
    "\n",
    "\n",
    "def plot_strategy_vs_buyhold(ticker: str, df: pd.DataFrame, pdf: PdfPages):\n",
    "    \"\"\"Strategy vs Buy & Hold with BOTH lines visible.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 7), facecolor=DarkTheme.BACKGROUND)\n",
    "    ax.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    strategy_norm = df['equity'] / df['equity'].iloc[0]\n",
    "    buyhold_norm = (1 + df['ret_1']).cumprod()\n",
    "\n",
    "    ax.plot(df.index, strategy_norm, color=DarkTheme.BLUE, linewidth=2,\n",
    "            label='Strategy', zorder=3)\n",
    "    ax.plot(df.index, buyhold_norm, color=DarkTheme.ORANGE, linewidth=2,\n",
    "            linestyle='--', label='Buy & Hold', zorder=2)\n",
    "\n",
    "    ax.fill_between(df.index, strategy_norm, buyhold_norm,\n",
    "                    where=(strategy_norm > buyhold_norm),\n",
    "                    color=DarkTheme.GREEN, alpha=0.2, label='Outperformance')\n",
    "    ax.fill_between(df.index, strategy_norm, buyhold_norm,\n",
    "                    where=(strategy_norm <= buyhold_norm),\n",
    "                    color=DarkTheme.RED, alpha=0.2, label='Underperformance')\n",
    "\n",
    "    ax.axhline(1.0, color=DarkTheme.TEXT_DIM, linewidth=1, linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax.set_title(f'{ticker} â€“ Strategy vs Buy & Hold (Walk-Forward)',\n",
    "                fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax.set_xlabel('Date', color=DarkTheme.TEXT)\n",
    "    ax.set_ylabel('Equity (indexed at 1.0)', color=DarkTheme.TEXT)\n",
    "    ax.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "             edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    reset_light_theme()\n",
    "\n",
    "\n",
    "def plot_cross_asset_comparison(all_results: Dict[str, pd.DataFrame], pdf: PdfPages):\n",
    "    \"\"\"Cross-asset strategy comparison.\"\"\"\n",
    "    setup_dark_theme()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), facecolor=DarkTheme.BACKGROUND)\n",
    "    ax.set_facecolor(DarkTheme.PANEL)\n",
    "\n",
    "    colors = [DarkTheme.BLUE, DarkTheme.ORANGE, DarkTheme.GREEN,\n",
    "              DarkTheme.RED, DarkTheme.PURPLE, DarkTheme.CYAN, DarkTheme.PINK]\n",
    "\n",
    "    for i, (name, res_df) in enumerate(all_results.items()):\n",
    "        if res_df.empty or 'equity' not in res_df.columns:\n",
    "            continue\n",
    "        normalized = res_df['equity'] / res_df['equity'].iloc[0]\n",
    "        ax.plot(res_df.index, normalized, color=colors[i % len(colors)],\n",
    "                linewidth=2, label=name)\n",
    "\n",
    "    ax.axhline(1.0, color=DarkTheme.TEXT_DIM, linewidth=1, linestyle='--', alpha=0.5)\n",
    "    ax.set_title('Strategy Equity Curves â€“ Cross Asset Comparison',\n",
    "                fontsize=14, color=DarkTheme.TEXT)\n",
    "    ax.set_xlabel('Date', color=DarkTheme.TEXT)\n",
    "    ax.set_ylabel('Equity (normalized)', color=DarkTheme.TEXT)\n",
    "    ax.legend(loc='upper left', facecolor=DarkTheme.PANEL,\n",
    "             edgecolor=DarkTheme.GRID, labelcolor=DarkTheme.TEXT)\n",
    "    ax.grid(True, alpha=0.3, color=DarkTheme.GRID)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(fig, facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    reset_light_theme()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED WEEKEND THETA TESTER (Now tests actually connected logic)\n",
    "# =============================================================================\n",
    "\n",
    "class WeekendThetaTester:\n",
    "    \"\"\"\n",
    "    Weekend theta factor tester with statistical significance.\n",
    "\n",
    "    NOW ACTUALLY TESTS THE WIRED WEEKEND THETA LOGIC (FIX #2).\n",
    "    v4.1: Uses deepcopy of caller's config to preserve all settings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ScientificConfig):\n",
    "        self.config = config\n",
    "        self.results = {}\n",
    "        self.returns_by_factor = {}\n",
    "        self.logger = Logger(config.logging)\n",
    "\n",
    "    def test_factors(self, df: pd.DataFrame, ticker: str,\n",
    "                     factors: List[float]) -> Dict[float, Dict[str, float]]:\n",
    "        \"\"\"Test multiple weekend theta factors.\"\"\"\n",
    "        import copy\n",
    "\n",
    "        self.logger.header(\"WEEKEND THETA FACTOR TESTING (v4 - NOW WIRED)\")\n",
    "        self.logger.info(f\"Testing {len(factors)} factors: {factors}\")\n",
    "\n",
    "        results = {}\n",
    "        returns_by_factor = {}\n",
    "\n",
    "        for i, factor in enumerate(factors):\n",
    "            self.logger.info(f\"\\n[{i+1}/{len(factors)}] Testing factor = {factor:.1f}\")\n",
    "\n",
    "            # FIX 2.3: Use deepcopy of caller's config to preserve all settings\n",
    "            # Only override weekend theta parameters\n",
    "            test_config = copy.deepcopy(self.config)\n",
    "            test_config.logging.level = LogLevel.QUIET\n",
    "            test_config.logging.show_progress = False\n",
    "            test_config.weekend_theta.weekend_factor = factor\n",
    "            test_config.weekend_theta.dte_7_factor = factor * 1.17\n",
    "            test_config.weekend_theta.dte_14_factor = factor\n",
    "            test_config.weekend_theta.dte_30_factor = factor * 0.83\n",
    "\n",
    "            try:\n",
    "                engine = ScientificStrategyEngine(test_config)\n",
    "                backtest_results = engine.run(df.copy(), ticker)\n",
    "\n",
    "                if backtest_results.empty:\n",
    "                    continue\n",
    "\n",
    "                metrics = MetricsCalculator.calculate_all(backtest_results, engine.ml)\n",
    "                returns = backtest_results['pnl'].values\n",
    "\n",
    "                ttest = SharpeStatistics.sharpe_ttest(returns)\n",
    "                bootstrap = SharpeStatistics.bootstrap_sharpe_ci(returns, n_bootstrap=2000)\n",
    "\n",
    "                results[factor] = {\n",
    "                    'sharpe': metrics.get('Sharpe', 0.0),\n",
    "                    'sortino': metrics.get('Sortino', 0.0),\n",
    "                    'total_return': metrics.get('Total Return', 0.0),\n",
    "                    'max_dd': metrics.get('Max Drawdown', 0.0),\n",
    "                    'win_rate': metrics.get('Win Rate', 0.0),\n",
    "                    'calmar': metrics.get('Calmar', 0.0),\n",
    "                    'sharpe_se': ttest['se'],\n",
    "                    'sharpe_tstat': ttest['t_stat'],\n",
    "                    'sharpe_pvalue': ttest['p_value'],\n",
    "                    'sharpe_sig_5pct': ttest['significant_5pct'],\n",
    "                    'sharpe_ci_lower': bootstrap['ci_lower'],\n",
    "                    'sharpe_ci_upper': bootstrap['ci_upper'],\n",
    "                    'avg_weekend_adj': metrics.get('Avg Weekend Theta Adj', 1.0)\n",
    "                }\n",
    "\n",
    "                returns_by_factor[factor] = returns\n",
    "\n",
    "                sig_marker = \"âœ“\" if ttest['significant_5pct'] else \"âœ—\"\n",
    "                self.logger.success(\n",
    "                    f\"Factor {factor:.1f}: Sharpe={results[factor]['sharpe']:.3f} \"\n",
    "                    f\"(t={ttest['t_stat']:.2f}, p={ttest['p_value']:.4f}) {sig_marker}\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed for factor={factor}: {e}\")\n",
    "\n",
    "        self.results = results\n",
    "        self.returns_by_factor = returns_by_factor\n",
    "        return results\n",
    "\n",
    "    def find_optimal_factor(self, metric: str = 'sharpe',\n",
    "                            require_significance: bool = True) -> Tuple[float, Dict]:\n",
    "        \"\"\"Find optimal factor.\"\"\"\n",
    "        if not self.results:\n",
    "            return None, {}\n",
    "\n",
    "        candidates = self.results.copy()\n",
    "\n",
    "        if require_significance:\n",
    "            candidates = {f: m for f, m in candidates.items()\n",
    "                         if m.get('sharpe_sig_5pct', False)}\n",
    "\n",
    "        if not candidates:\n",
    "            candidates = self.results\n",
    "\n",
    "        optimal_factor = max(candidates.keys(),\n",
    "                            key=lambda f: candidates[f].get(metric, -999))\n",
    "\n",
    "        return optimal_factor, candidates[optimal_factor]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED REPORT GENERATOR (25+ pages with new plots)\n",
    "# =============================================================================\n",
    "\n",
    "class ScientificReportGenerator:\n",
    "    \"\"\"\n",
    "    Generate comprehensive PDF reports.\n",
    "\n",
    "    Now includes:\n",
    "    - All v3 pages (preserved)\n",
    "    - NEW: ML Lift Curve\n",
    "    - NEW: Turnover & Exposure analysis\n",
    "    - NEW: Confusion Matrix by Regime\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ticker: str, df: pd.DataFrame, pdf: PdfPages,\n",
    "                 config: ScientificConfig, ml_engine: MLSignalGenerator = None,\n",
    "                 ml_predictions: np.ndarray = None, ml_outcomes: np.ndarray = None):\n",
    "        self.ticker = ticker\n",
    "        self.df = df.copy()\n",
    "        self.pdf = pdf\n",
    "        self.config = config\n",
    "        self.ml_engine = ml_engine\n",
    "        self.metrics = MetricsCalculator.calculate_all(df, ml_engine)\n",
    "        self.ml_predictions = ml_predictions\n",
    "        self.ml_outcomes = ml_outcomes\n",
    "\n",
    "        if 'strategy' in self.df.columns:\n",
    "            self.df['trade_id'] = (self.df['strategy'] != self.df['strategy'].shift(1)).cumsum()\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate all report pages.\"\"\"\n",
    "        print(f\"  Building report for {self.ticker}...\")\n",
    "\n",
    "        # Standard pages (light theme) - Pages 1-10\n",
    "        self._page_executive_summary()\n",
    "        self._page_rolling_performance()\n",
    "        self._page_drawdown_analysis()\n",
    "        self._page_strategy_attribution()\n",
    "        self._page_regime_analysis()\n",
    "        self._page_risk_decomposition()\n",
    "        self._page_monthly_heatmap()\n",
    "        self._page_trade_analysis()\n",
    "        self._page_improvement_dashboard()\n",
    "        self._page_final_summary()\n",
    "\n",
    "        # Fixed visualizations (dark theme) - Pages 11-14\n",
    "        plot_strategy_vs_buyhold(self.ticker, self.df, self.pdf)\n",
    "        plot_price_with_trade_entries(self.ticker, self.df, self.pdf)\n",
    "        plot_monthly_returns_line(self.ticker, self.df, self.pdf)\n",
    "\n",
    "        # NEW: Turnover & Exposure - Page 15\n",
    "        plot_turnover_exposure(self.df, self.ticker, self.pdf)\n",
    "\n",
    "        # Reliability diagram - Page 16\n",
    "        if self.ml_predictions is not None and len(self.ml_predictions) > 50:\n",
    "            plot_reliability_diagram(self.ml_predictions, self.ml_outcomes,\n",
    "                                    n_bins=self.config.reliability_n_bins,\n",
    "                                    ticker=self.ticker, pdf=self.pdf)\n",
    "\n",
    "        # Sharpe significance - Page 17\n",
    "        returns = self.df['pnl'].values\n",
    "        if len(returns) > 30:\n",
    "            plot_sharpe_significance(returns, ticker=self.ticker, pdf=self.pdf)\n",
    "\n",
    "        # NEW: ML Lift Curve - Page 18\n",
    "        if self.ml_predictions is not None and len(self.ml_predictions) > 50:\n",
    "            returns_aligned = self.df['ret_1'].values[:len(self.ml_predictions)]\n",
    "            plot_ml_lift_curve(self.ml_predictions, self.ml_outcomes, returns_aligned,\n",
    "                              ticker=self.ticker, pdf=self.pdf)\n",
    "\n",
    "        # NEW: Confusion by Regime - Page 19\n",
    "        if self.ml_predictions is not None and len(self.ml_predictions) > 50:\n",
    "            plot_confusion_by_regime(self.df, self.ml_predictions, self.ml_outcomes,\n",
    "                                    ticker=self.ticker, pdf=self.pdf)\n",
    "\n",
    "    def _save(self, fig):\n",
    "        self.pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    def _page_executive_summary(self):\n",
    "        \"\"\"Page 1: Executive summary.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig = plt.figure(figsize=(11, 8.5))\n",
    "        gs = gridspec.GridSpec(3, 2, height_ratios=[0.5, 2, 1], hspace=0.3)\n",
    "\n",
    "        ax_title = fig.add_subplot(gs[0, :])\n",
    "        ax_title.axis('off')\n",
    "        ax_title.text(0.5, 0.7, f\"{self.ticker}\", fontsize=28, fontweight='bold',\n",
    "                     ha='center', va='center', color=LightTheme.PRIMARY)\n",
    "        ax_title.text(0.5, 0.2, f\"{FRAMEWORK_NAME} â€” Performance Report\",\n",
    "                     fontsize=14, ha='center', va='center', color=LightTheme.SECONDARY)\n",
    "\n",
    "        ax_eq = fig.add_subplot(gs[1, :])\n",
    "        ax_eq.plot(self.df.index, self.df['equity'], color=LightTheme.PRIMARY,\n",
    "                   lw=2.5, label='Strategy')\n",
    "        ax_eq.fill_between(self.df.index, self.df['equity'].iloc[0], self.df['equity'],\n",
    "                          alpha=0.1, color=LightTheme.PRIMARY)\n",
    "        ax_eq.axhline(self.df['equity'].iloc[0], color='gray', ls='--', alpha=0.5,\n",
    "                     label='Starting Capital')\n",
    "        ax_eq.set_title(\"Cumulative Equity\", fontsize=14, fontweight='bold', pad=10)\n",
    "        ax_eq.set_ylabel(\"Equity ($)\")\n",
    "        ax_eq.legend(loc='upper left')\n",
    "        ax_eq.grid(True, alpha=0.3)\n",
    "        ax_eq.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "        ax_met = fig.add_subplot(gs[2, :])\n",
    "        ax_met.axis('off')\n",
    "        m = self.metrics\n",
    "\n",
    "        returns = self.df['pnl'].values\n",
    "        ttest = SharpeStatistics.sharpe_ttest(returns)\n",
    "        sharpe_sig = \"âœ“\" if ttest['significant_5pct'] else \"\"\n",
    "\n",
    "        # FIX #3: Show OOS AUC\n",
    "        oos_auc = m.get('ML OOS AUC (Global)', m.get('ML OOS AUC (Last)', 0.5))\n",
    "\n",
    "        metrics_data = [\n",
    "            ['Sharpe Ratio', f\"{m.get('Sharpe', 0):.3f} {sharpe_sig}\",\n",
    "             'Sortino Ratio', f\"{m.get('Sortino', 0):.3f}\"],\n",
    "            ['Total Return', f\"{m.get('Total Return', 0):+.2%}\",\n",
    "             'CAGR', f\"{m.get('CAGR', 0):+.2%}\"],\n",
    "            ['Max Drawdown', f\"{m.get('Max Drawdown', 0):.2%}\",\n",
    "             'Win Rate', f\"{m.get('Win Rate', 0):.1%}\"],\n",
    "            ['ML OOS AUC', f\"{oos_auc:.4f}\",\n",
    "             'Sharpe p-value', f\"{ttest['p_value']:.4f}\"]\n",
    "        ]\n",
    "        table = ax_met.table(cellText=metrics_data, loc='center', cellLoc='center',\n",
    "                            colWidths=[0.2, 0.15, 0.2, 0.15])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(11)\n",
    "        table.scale(1.2, 2.0)\n",
    "        for i in range(4):\n",
    "            table[(i, 0)].set_facecolor('#e8f4fd')\n",
    "            table[(i, 2)].set_facecolor('#e8f4fd')\n",
    "\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_rolling_performance(self):\n",
    "        \"\"\"Page 2: Rolling Sharpe and Sortino.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(11, 8.5), sharex=True)\n",
    "\n",
    "        roll_sharpe = self.df['pnl'].rolling(126).apply(\n",
    "            lambda x: x.mean()/x.std()*np.sqrt(252) if x.std() > 0 else 0)\n",
    "        axes[0].plot(self.df.index, roll_sharpe, color=LightTheme.PRIMARY, lw=2)\n",
    "        axes[0].axhline(0, color='black', ls='--', alpha=0.5)\n",
    "        axes[0].axhline(1.0, color=LightTheme.POSITIVE, ls='--', alpha=0.5, label='Target: 1.0')\n",
    "        axes[0].fill_between(self.df.index, 0, roll_sharpe, where=roll_sharpe > 0,\n",
    "                            alpha=0.3, color=LightTheme.POSITIVE)\n",
    "        axes[0].fill_between(self.df.index, 0, roll_sharpe, where=roll_sharpe < 0,\n",
    "                            alpha=0.3, color=LightTheme.NEGATIVE)\n",
    "        axes[0].set_title(\"Rolling 6-Month Sharpe Ratio\", fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel(\"Sharpe Ratio\")\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        def rolling_sortino(x):\n",
    "            down = x[x < 0]\n",
    "            down_std = down.std() if len(down) > 2 else x.std()\n",
    "            return x.mean() / down_std * np.sqrt(252) if down_std > 0 else 0\n",
    "\n",
    "        roll_sortino = self.df['pnl'].rolling(126).apply(rolling_sortino)\n",
    "        axes[1].plot(self.df.index, roll_sortino, color=LightTheme.SECONDARY, lw=2)\n",
    "        axes[1].axhline(0, color='black', ls='--', alpha=0.5)\n",
    "        axes[1].axhline(1.5, color=LightTheme.POSITIVE, ls='--', alpha=0.5, label='Target: 1.5')\n",
    "        axes[1].fill_between(self.df.index, 0, roll_sortino, where=roll_sortino > 0,\n",
    "                            alpha=0.3, color=LightTheme.POSITIVE)\n",
    "        axes[1].fill_between(self.df.index, 0, roll_sortino, where=roll_sortino < 0,\n",
    "                            alpha=0.3, color=LightTheme.NEGATIVE)\n",
    "        axes[1].set_title(\"Rolling 6-Month Sortino Ratio\", fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel(\"Sortino Ratio\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_drawdown_analysis(self):\n",
    "        \"\"\"Page 3: Drawdown analysis.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(11, 8.5))\n",
    "\n",
    "        dd = self.df['drawdown'] * 100\n",
    "        axes[0].fill_between(self.df.index, 0, dd, color=LightTheme.NEGATIVE, alpha=0.7)\n",
    "        axes[0].plot(self.df.index, dd, color='darkred', lw=1)\n",
    "        axes[0].axhline(-10, color='orange', ls='--', alpha=0.7, label='Warning: -10%')\n",
    "        axes[0].set_title(\"Drawdown Over Time\", fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel(\"Drawdown (%)\")\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        axes[1].hist(dd, bins=50, color=LightTheme.NEGATIVE, alpha=0.7, edgecolor='darkred')\n",
    "        axes[1].axvline(dd.quantile(0.05), color='black', ls='--', lw=2,\n",
    "                       label=f'5th Percentile: {dd.quantile(0.05):.1f}%')\n",
    "        axes[1].set_title(\"Drawdown Distribution\", fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel(\"Drawdown (%)\")\n",
    "        axes[1].set_ylabel(\"Frequency\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_strategy_attribution(self):\n",
    "        \"\"\"Page 4: Strategy allocation and P&L.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(11, 8.5))\n",
    "\n",
    "        if 'strategy' in self.df.columns:\n",
    "            strat_counts = self.df['strategy'].value_counts()\n",
    "            colors_list = [LightTheme.PRIMARY, LightTheme.SECONDARY, LightTheme.ACCENT,\n",
    "                          LightTheme.POSITIVE, LightTheme.WARNING, LightTheme.NEGATIVE][:len(strat_counts)]\n",
    "            axes[0].pie(strat_counts.values, labels=strat_counts.index, autopct='%1.1f%%',\n",
    "                       colors=colors_list, startangle=90)\n",
    "            axes[0].set_title(\"Strategy Allocation\", fontsize=14, fontweight='bold')\n",
    "\n",
    "            strat_pnl = self.df.groupby('strategy')['pnl'].sum().sort_values(ascending=True)\n",
    "            bar_colors = [LightTheme.POSITIVE if x > 0 else LightTheme.NEGATIVE\n",
    "                         for x in strat_pnl.values]\n",
    "            axes[1].barh(strat_pnl.index, strat_pnl.values * 100, color=bar_colors)\n",
    "            axes[1].axvline(0, color='black', lw=1)\n",
    "            axes[1].set_title(\"P&L by Strategy (%)\", fontsize=14, fontweight='bold')\n",
    "            axes[1].set_xlabel(\"Cumulative P&L (%)\")\n",
    "            axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_regime_analysis(self):\n",
    "        \"\"\"Page 5: Regime detection (now without leakage).\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig = plt.figure(figsize=(11, 8.5))\n",
    "        gs = gridspec.GridSpec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "        if 'regime' not in self.df.columns:\n",
    "            ax = fig.add_subplot(gs[:, :])\n",
    "            ax.text(0.5, 0.5, \"No regime data available\", ha='center', va='center', fontsize=14)\n",
    "            ax.axis('off')\n",
    "            self._save(fig)\n",
    "            return\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        regime_map = {'Bull': 3, 'Neutral': 2, 'Bear': 1, 'Crisis': 0}\n",
    "        regime_numeric = self.df['regime'].map(regime_map).fillna(2)\n",
    "        ax1.fill_between(self.df.index, 0, regime_numeric, alpha=0.5,\n",
    "                        color=LightTheme.PRIMARY, step='post')\n",
    "        ax1.set_yticks([0, 1, 2, 3])\n",
    "        ax1.set_yticklabels(['CRISIS', 'BEAR', 'NEUTRAL', 'BULL'])\n",
    "        ax1.set_title(\"Market Regime (HMM - No Leakage in v4)\", fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[1, 0])\n",
    "        regime_counts = self.df['regime'].value_counts()\n",
    "        color_map = {'Bull': LightTheme.POSITIVE, 'Neutral': LightTheme.WARNING,\n",
    "                    'Bear': LightTheme.NEGATIVE, 'Crisis': 'darkred'}\n",
    "        bar_colors = [color_map.get(r, 'gray') for r in regime_counts.index]\n",
    "        ax2.bar(regime_counts.index, regime_counts.values, color=bar_colors)\n",
    "        ax2.set_title(\"Regime Distribution\", fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel(\"Days\")\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[1, 1])\n",
    "        regime_pnl = self.df.groupby('regime')['pnl'].agg(['mean', 'std'])\n",
    "        regime_pnl['sharpe'] = regime_pnl['mean'] / regime_pnl['std'] * np.sqrt(252)\n",
    "        x = range(len(regime_pnl))\n",
    "        bar_colors = [color_map.get(r, 'gray') for r in regime_pnl.index]\n",
    "        ax3.bar(x, regime_pnl['sharpe'], color=bar_colors)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(regime_pnl.index)\n",
    "        ax3.axhline(0, color='black', lw=1)\n",
    "        ax3.set_title(\"Sharpe by Regime\", fontsize=12, fontweight='bold')\n",
    "        ax3.set_ylabel(\"Sharpe Ratio\")\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_risk_decomposition(self):\n",
    "        \"\"\"Page 6: Risk metrics.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))\n",
    "\n",
    "        r = self.df['pnl']\n",
    "\n",
    "        axes[0, 0].hist(r * 100, bins=50, color=LightTheme.PRIMARY, alpha=0.7, edgecolor='white')\n",
    "        axes[0, 0].axvline(r.mean() * 100, color=LightTheme.POSITIVE, lw=2, ls='--',\n",
    "                          label=f'Mean: {r.mean()*100:.3f}%')\n",
    "        axes[0, 0].axvline(r.quantile(0.05) * 100, color=LightTheme.NEGATIVE, lw=2, ls='--',\n",
    "                          label=f'VaR 95%: {r.quantile(0.05)*100:.3f}%')\n",
    "        axes[0, 0].set_title(\"Daily P&L Distribution\", fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel(\"Daily P&L (%)\")\n",
    "        axes[0, 0].legend(fontsize=8)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        probplot(r, dist=\"norm\", plot=axes[0, 1])\n",
    "        axes[0, 1].set_title(\"Q-Q Plot vs Normal\", fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        roll_vol = r.rolling(20).std() * np.sqrt(252) * 100\n",
    "        axes[1, 0].plot(self.df.index, roll_vol, color=LightTheme.PRIMARY, lw=1.5)\n",
    "        axes[1, 0].axhline(12, color=LightTheme.POSITIVE, ls='--', label='Target: 12%')\n",
    "        axes[1, 0].fill_between(self.df.index, roll_vol, 12, where=roll_vol > 12,\n",
    "                               alpha=0.3, color=LightTheme.NEGATIVE)\n",
    "        axes[1, 0].fill_between(self.df.index, roll_vol, 12, where=roll_vol < 12,\n",
    "                               alpha=0.3, color=LightTheme.POSITIVE)\n",
    "        axes[1, 0].set_title(\"Rolling Volatility (ART)\", fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].set_ylabel(\"Annualized Vol (%)\")\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        axes[1, 1].axis('off')\n",
    "        m = self.metrics\n",
    "        risk_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['VaR 95%', f\"{m.get('VaR 95%', 0)*100:.3f}%\"],\n",
    "            ['ES 95%', f\"{m.get('ES 95%', 0)*100:.3f}%\"],\n",
    "            ['Skewness', f\"{m.get('Skewness', 0):.3f}\"],\n",
    "            ['Kurtosis', f\"{m.get('Kurtosis', 0):.3f}\"],\n",
    "            ['Omega Ratio', f\"{m.get('Omega', 0):.3f}\"],\n",
    "            ['Profit Factor', f\"{m.get('Profit Factor', 0):.3f}\"]\n",
    "        ]\n",
    "        table = axes[1, 1].table(cellText=risk_data, loc='center', cellLoc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(11)\n",
    "        table.scale(1.2, 2.0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_monthly_heatmap(self):\n",
    "        \"\"\"Page 7: Monthly returns heatmap.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(11, 8.5))\n",
    "\n",
    "        monthly = self.df['pnl'].resample('M').sum() * 100\n",
    "        monthly_df = pd.DataFrame({\n",
    "            'Year': monthly.index.year,\n",
    "            'Month': monthly.index.month,\n",
    "            'Return': monthly.values\n",
    "        })\n",
    "        pivot = monthly_df.pivot(index='Year', columns='Month', values='Return')\n",
    "        pivot.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'][:len(pivot.columns)]\n",
    "\n",
    "        sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn', center=0, ax=ax,\n",
    "                   cbar_kws={'label': 'Monthly Return (%)'})\n",
    "        ax.set_title(\"Monthly Returns Heatmap (%)\", fontsize=14, fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_trade_analysis(self):\n",
    "        \"\"\"Page 8: Top trades.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(11, 8.5))\n",
    "        ax.axis('off')\n",
    "\n",
    "        if 'trade_id' not in self.df.columns:\n",
    "            ax.text(0.5, 0.5, \"No trade data\", ha='center', va='center', fontsize=14)\n",
    "            self._save(fig)\n",
    "            return\n",
    "\n",
    "        trades = self.df.groupby(['trade_id', 'strategy'])['pnl'].sum().reset_index()\n",
    "        trades = trades[trades['strategy'] != 'Cash'].sort_values('pnl', ascending=False)\n",
    "\n",
    "        if len(trades) == 0:\n",
    "            ax.text(0.5, 0.5, \"No trades executed\", ha='center', va='center', fontsize=14)\n",
    "            self._save(fig)\n",
    "            return\n",
    "\n",
    "        top10 = trades.head(10)\n",
    "        bottom10 = trades.tail(10)\n",
    "        combined = pd.concat([top10, bottom10])\n",
    "\n",
    "        table_data = [['Rank', 'Strategy', 'P&L (%)']]\n",
    "        for i, (_, row) in enumerate(combined.iterrows()):\n",
    "            rank = i + 1 if i < 10 else f\"B{i-9}\"\n",
    "            table_data.append([rank, row['strategy'], f\"{row['pnl']*100:+.4f}%\"])\n",
    "\n",
    "        table = ax.table(cellText=table_data, loc='center', cellLoc='center',\n",
    "                        colWidths=[0.15, 0.45, 0.2])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.1, 1.8)\n",
    "\n",
    "        ax.set_title(\"Top 10 Winners & Losers\", fontsize=16, fontweight='bold', pad=20)\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_improvement_dashboard(self):\n",
    "        \"\"\"Page 9: Improvements dashboard.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig = plt.figure(figsize=(11, 8.5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axis('off')\n",
    "\n",
    "        m = self.metrics\n",
    "        oos_auc = m.get('ML OOS AUC (Global)', m.get('ML OOS AUC (Mean Window)', 0.5))\n",
    "\n",
    "        improvements = [\n",
    "            ('1. Robust ML (Lasso Logistic)', f\"OOS AUC: {oos_auc:.4f}\",\n",
    "             'âœ…' if oos_auc > 0.52 else 'âš ï¸'),\n",
    "            ('2. HMM Regime (No Leakage v4)', \"Fixed: Train-only fitting\", 'âœ…'),\n",
    "            ('3. Parkinson/GK Vol Estimators', \"Using High-Low data\", 'âœ…'),\n",
    "            ('4. Vol Percentile (renamed)', \"Accurate nomenclature\", 'âœ…'),\n",
    "            ('5. Auto-Regressive Risk Targeting', f\"Realized: {m.get('Realized Vol', 0)*100:.1f}%\",\n",
    "             'âœ…' if m.get('Vol Target Hit', False) else 'âš ï¸'),\n",
    "            ('6. Weekend Theta WIRED', f\"Avg Adj: {m.get('Avg Weekend Theta Adj', 1.0):.4f}\", 'âœ…'),\n",
    "            ('7. Strategy Leverage Diff', \"Per-strategy scaling\", 'âœ…'),\n",
    "            ('8. OOS AUC Reporting', \"Test AUC, not train\", 'âœ…')\n",
    "        ]\n",
    "\n",
    "        table_data = [['Improvement', 'Metric', 'Status']] + [list(imp) for imp in improvements]\n",
    "        table = ax.table(cellText=table_data, loc='center', cellLoc='left',\n",
    "                        colWidths=[0.4, 0.35, 0.1])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(11)\n",
    "        table.scale(1.1, 2.2)\n",
    "\n",
    "        ax.set_title(f\"v{FRAMEWORK_VERSION} Fixes & Improvements Dashboard\", fontsize=16, fontweight='bold', y=0.95)\n",
    "        self._save(fig)\n",
    "\n",
    "    def _page_final_summary(self):\n",
    "        \"\"\"Page 10: Final summary.\"\"\"\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(11, 8.5))\n",
    "        ax.axis('off')\n",
    "\n",
    "        m = self.metrics\n",
    "        sharpe = m.get('Sharpe', 0)\n",
    "\n",
    "        returns = self.df['pnl'].values\n",
    "        ttest = SharpeStatistics.sharpe_ttest(returns)\n",
    "        bootstrap = SharpeStatistics.bootstrap_sharpe_ci(returns)\n",
    "\n",
    "        if sharpe > 1.0 and ttest['significant_5pct']:\n",
    "            perf_grade = \"EXCELLENT (Significant)\"\n",
    "        elif sharpe > 0.5 and ttest['significant_5pct']:\n",
    "            perf_grade = \"GOOD (Significant)\"\n",
    "        elif sharpe > 0.5:\n",
    "            perf_grade = \"DEVELOPING\"\n",
    "        elif sharpe > 0:\n",
    "            perf_grade = \"WEAK POSITIVE\"\n",
    "        else:\n",
    "            perf_grade = \"NEEDS IMPROVEMENT\"\n",
    "\n",
    "        summary_text = f\"\"\"\n",
    "        {self.ticker} - FINAL SUMMARY (v{FRAMEWORK_VERSION})\n",
    "\n",
    "        Core Metrics:\n",
    "        - Sharpe Ratio:   {sharpe:.4f}\n",
    "        - Sortino Ratio:  {m.get('Sortino', 0):.4f}\n",
    "        - Total Return:   {m.get('Total Return', 0):+.2%}\n",
    "        - Max Drawdown:   {m.get('Max Drawdown', 0):.2%}\n",
    "\n",
    "        Statistical Significance:\n",
    "        - t-stat:         {ttest['t_stat']:.4f}\n",
    "        - p-value:        {ttest['p_value']:.6f}\n",
    "        - 95% CI:         [{bootstrap['ci_lower']:.4f}, {bootstrap['ci_upper']:.4f}]\n",
    "        - Significant:    {'Yes' if ttest['significant_5pct'] else 'No'}\n",
    "\n",
    "        ML Performance (OOS):\n",
    "        - Global AUC:     {m.get('ML OOS AUC (Global)', 0.5):.4f}\n",
    "\n",
    "        GRADE: {perf_grade}\n",
    "        \"\"\"\n",
    "\n",
    "        ax.text(0.5, 0.5, summary_text.strip(), ha='center', va='center', fontsize=13,\n",
    "               fontfamily='monospace',\n",
    "               bbox=dict(facecolor=LightTheme.PRIMARY, alpha=0.95, boxstyle='round,pad=0.5'),\n",
    "               color='white')\n",
    "\n",
    "        self._save(fig)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PORTFOLIO SUMMARY GENERATOR (Preserved)\n",
    "# =============================================================================\n",
    "\n",
    "class PortfolioSummaryGenerator:\n",
    "    \"\"\"Generate portfolio-level summary.\"\"\"\n",
    "\n",
    "    def __init__(self, portfolio_metrics: List[Dict], all_results: Dict[str, pd.DataFrame],\n",
    "                 pdf: PdfPages):\n",
    "        self.metrics = pd.DataFrame(portfolio_metrics)\n",
    "        self.all_results = all_results\n",
    "        self.pdf = pdf\n",
    "\n",
    "    def generate(self):\n",
    "        self._page_summary_table()\n",
    "        self._page_comparison_charts()\n",
    "        plot_cross_asset_comparison(self.all_results, self.pdf)\n",
    "\n",
    "    def _page_summary_table(self):\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(13.69, 8.27))\n",
    "        ax.axis('off')\n",
    "\n",
    "        ax.text(0.5, 0.96, \"Portfolio Performance Summary\", ha='center', fontsize=24,\n",
    "               fontweight='bold', transform=ax.transAxes, color=LightTheme.PRIMARY)\n",
    "        ax.text(0.5, 0.91, \"Scientific Options Framework v4.2 â€” All Assets\", ha='center',\n",
    "               fontsize=12, transform=ax.transAxes, color=LightTheme.SECONDARY)\n",
    "\n",
    "        show = self.metrics.copy()\n",
    "\n",
    "        # Format columns that exist (handle missing gracefully)\n",
    "        if 'Return' in show.columns:\n",
    "            show['Return'] = show['Return'].map('{:+.2%}'.format)\n",
    "        if 'Sharpe' in show.columns:\n",
    "            show['Sharpe'] = show['Sharpe'].map('{:.4f}'.format)\n",
    "        if 'Sortino' in show.columns:\n",
    "            show['Sortino'] = show['Sortino'].map('{:.4f}'.format)\n",
    "        if 'MaxDD' in show.columns:\n",
    "            show['MaxDD'] = show['MaxDD'].map('{:.2%}'.format)\n",
    "        if 'WinRate' in show.columns:\n",
    "            show['WinRate'] = show['WinRate'].map('{:.1%}'.format)\n",
    "        if 'OOS_AUC' in show.columns:\n",
    "            show['OOS_AUC'] = show['OOS_AUC'].map('{:.4f}'.format)\n",
    "        if 'VaR_Loss' in show.columns:\n",
    "            show['VaR_Loss'] = show['VaR_Loss'].map('{:.4f}'.format)\n",
    "        if 'ES_Loss' in show.columns:\n",
    "            show['ES_Loss'] = show['ES_Loss'].map('{:.4f}'.format)\n",
    "        if 'SharpeSig' in show.columns:\n",
    "            show['SharpeSig'] = show['SharpeSig'].map(lambda x: 'âœ“' if x else '')\n",
    "\n",
    "        # Build column list from what's available\n",
    "        possible_cols = ['Asset', 'Return', 'Sharpe', 'Sortino', 'MaxDD', 'WinRate',\n",
    "                         'OOS_AUC', 'VaR_Loss', 'ES_Loss', 'SharpeSig']\n",
    "        cols = [c for c in possible_cols if c in show.columns]\n",
    "        show = show[cols]\n",
    "\n",
    "        table_data = [show.columns.tolist()] + show.values.tolist()\n",
    "        table = ax.table(cellText=table_data, loc='center', bbox=[0.05, 0.20, 0.90, 0.65])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1, 2.2)\n",
    "\n",
    "        for j in range(len(show.columns)):\n",
    "            table[(0, j)].set_facecolor(LightTheme.PRIMARY)\n",
    "            table[(0, j)].get_text().set_color('white')\n",
    "\n",
    "        self.pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    def _page_comparison_charts(self):\n",
    "        reset_light_theme()\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(13.69, 8.27))\n",
    "\n",
    "        # Sharpe chart (always available)\n",
    "        colors_pos_neg = [LightTheme.POSITIVE if x > 0 else LightTheme.NEGATIVE\n",
    "                        for x in self.metrics['Sharpe']]\n",
    "        axes[0, 0].barh(self.metrics['Asset'], self.metrics['Sharpe'], color=colors_pos_neg)\n",
    "        axes[0, 0].axvline(0, color='black', lw=1)\n",
    "        axes[0, 0].set_title(\"Sharpe Ratio by Asset\", fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        # OOS AUC or Sortino (if available)\n",
    "        if 'OOS_AUC' in self.metrics.columns:\n",
    "            axes[0, 1].barh(self.metrics['Asset'], self.metrics['OOS_AUC'],\n",
    "                           color=LightTheme.SECONDARY)\n",
    "            axes[0, 1].axvline(0.5, color='black', ls='--', alpha=0.5)\n",
    "            axes[0, 1].set_title(\"ML OOS AUC by Asset\", fontsize=12, fontweight='bold')\n",
    "        elif 'Sortino' in self.metrics.columns:\n",
    "            colors_pos_neg = [LightTheme.POSITIVE if x > 0 else LightTheme.NEGATIVE\n",
    "                            for x in self.metrics['Sortino']]\n",
    "            axes[0, 1].barh(self.metrics['Asset'], self.metrics['Sortino'], color=colors_pos_neg)\n",
    "            axes[0, 1].axvline(0, color='black', lw=1)\n",
    "            axes[0, 1].set_title(\"Sortino Ratio by Asset\", fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'No additional ratio data', ha='center', va='center')\n",
    "            axes[0, 1].set_title(\"Additional Metrics\", fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        # Returns chart\n",
    "        colors_pos_neg = [LightTheme.POSITIVE if x > 0 else LightTheme.NEGATIVE\n",
    "                        for x in self.metrics['Return']]\n",
    "        axes[1, 0].barh(self.metrics['Asset'], self.metrics['Return'] * 100, color=colors_pos_neg)\n",
    "        axes[1, 0].axvline(0, color='black', lw=1)\n",
    "        axes[1, 0].set_title(\"Total Return (%) by Asset\", fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        # VaR Loss or WinRate\n",
    "        if 'VaR_Loss' in self.metrics.columns:\n",
    "            axes[1, 1].barh(self.metrics['Asset'], self.metrics['VaR_Loss'] * 100,\n",
    "                           color=LightTheme.NEGATIVE)\n",
    "            axes[1, 1].set_title(\"VaR 95% Loss (%) by Asset\", fontsize=12, fontweight='bold')\n",
    "        elif 'WinRate' in self.metrics.columns:\n",
    "            axes[1, 1].barh(self.metrics['Asset'], self.metrics['WinRate'] * 100,\n",
    "                           color=LightTheme.SECONDARY)\n",
    "            axes[1, 1].axvline(50, color='black', ls='--', alpha=0.5)\n",
    "            axes[1, 1].set_title(\"Win Rate (%) by Asset\", fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'No risk data', ha='center', va='center')\n",
    "            axes[1, 1].set_title(\"Risk Metrics\", fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        plt.suptitle(\"Cross-Asset Performance\", fontsize=14, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        self.pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(FRAMEWORK_NAME)\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"FIXES APPLIED (v4.0 â†’ v4.2):\")\n",
    "    print(\"  âœ… HMM: Fits on train only, predicts on test (no leakage)\")\n",
    "    print(\"  âœ… ML: Reports OOS AUC (not train), drops last training row\")\n",
    "    print(\"  âœ… Weekend Theta: Actually affects PnL on Fridays\")\n",
    "    print(\"  âœ… Strategy Leverage: Different scaling per strategy type\")\n",
    "    print(\"  âœ… Regime Mapping: States named by mean return (Bull/Neutral/Bear)\")\n",
    "    print(\"  âœ… Vol Percentile: Renamed from VRP, uses searchsorted\")\n",
    "    print(\"  âœ… VaR/ES: Clear sign conventions + loss versions\")\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    config = ScientificConfig()\n",
    "    config.logging.level = LogLevel.NORMAL\n",
    "    config.train_window = 252\n",
    "    config.test_window = 21\n",
    "\n",
    "    TOP_ASSETS = [\n",
    "        \"AUDUSD\",\"GBPUSD\",\"USA500.IDXUSD\", \"XAUUSD\", \"BTCUSD\", \"USATECH.IDXUSD\",\n",
    "        \"EURUSD\", \"DIESEL\",\"USTBOND\"\n",
    "    ]\n",
    "\n",
    "    loader = DataLoader(config)\n",
    "    logger = Logger(config.logging)\n",
    "    portfolio_metrics = []\n",
    "    all_results = {}\n",
    "\n",
    "    for ticker in TOP_ASSETS:\n",
    "        logger.header(f\"Processing: {ticker}\")\n",
    "\n",
    "        try:\n",
    "            df = loader.load(ticker)\n",
    "            logger.info(f\"Loaded {len(df):,} daily bars\")\n",
    "\n",
    "            engine = ScientificStrategyEngine(config)\n",
    "            results = engine.run(df, ticker)\n",
    "\n",
    "            if results.empty:\n",
    "                logger.warning(f\"No results for {ticker}\")\n",
    "                continue\n",
    "\n",
    "            all_results[ticker] = results.copy()\n",
    "            metrics = MetricsCalculator.calculate_all(results, engine.ml)\n",
    "\n",
    "            ml_preds, ml_outcomes = engine.get_ml_calibration_data()\n",
    "\n",
    "            returns = results['pnl'].values\n",
    "            ttest = SharpeStatistics.sharpe_ttest(returns)\n",
    "            bootstrap = SharpeStatistics.bootstrap_sharpe_ci(returns, n_bootstrap=2000)\n",
    "\n",
    "            logger.info(f\"\\nRESULTS:\")\n",
    "            logger.info(f\"â”œâ”€ Sharpe:        {metrics.get('Sharpe', 0):.4f}\")\n",
    "            logger.info(f\"â”œâ”€ t-stat:        {ttest['t_stat']:.4f}\")\n",
    "            logger.info(f\"â”œâ”€ p-value:       {ttest['p_value']:.6f}\")\n",
    "            logger.info(f\"â”œâ”€ ML OOS AUC:    {engine.get_ml_global_oos_auc():.4f}\")\n",
    "            logger.info(f\"â”œâ”€ Total Return:  {metrics.get('Total Return', 0):+.2%}\")\n",
    "            logger.info(f\"â””â”€ Max Drawdown:  {metrics.get('Max Drawdown', 0):.2%}\")\n",
    "\n",
    "            # Generate report - use version in filename\n",
    "            report_path = config.report_dir / f\"{ticker.replace('.', '_')}_Report_v{FRAMEWORK_VERSION.replace('.', '_')}.pdf\"\n",
    "            with PdfPages(report_path) as pdf:\n",
    "                report = ScientificReportGenerator(\n",
    "                    ticker, results, pdf, config,\n",
    "                    ml_engine=engine.ml,\n",
    "                    ml_predictions=ml_preds, ml_outcomes=ml_outcomes\n",
    "                )\n",
    "                report.generate()\n",
    "\n",
    "            logger.success(f\"Report saved: {report_path.name}\")\n",
    "\n",
    "            portfolio_metrics.append({\n",
    "                'Asset': ticker,\n",
    "                'Return': metrics.get('Total Return', 0),\n",
    "                'Sharpe': metrics.get('Sharpe', 0),\n",
    "                'Sortino': metrics.get('Sortino', 0),\n",
    "                'MaxDD': metrics.get('Max Drawdown', 0),\n",
    "                'WinRate': metrics.get('Win Rate', 0),\n",
    "                'OOS_AUC': engine.get_ml_global_oos_auc(),\n",
    "                'SharpeSig': ttest['significant_5pct'],\n",
    "                'SharpePval': ttest['p_value'],\n",
    "                'SharpeCI_L': bootstrap['ci_lower'],\n",
    "                'SharpeCI_U': bootstrap['ci_upper']\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Portfolio summary\n",
    "    if portfolio_metrics:\n",
    "        logger.header(\"PORTFOLIO SUMMARY\")\n",
    "\n",
    "        summary_path = config.report_dir / f\"Portfolio_Summary_v{FRAMEWORK_VERSION.replace('.', '_')}.pdf\"\n",
    "        with PdfPages(summary_path) as pdf:\n",
    "            summary = PortfolioSummaryGenerator(portfolio_metrics, all_results, pdf)\n",
    "            summary.generate()\n",
    "\n",
    "        logger.success(f\"Portfolio Summary saved: {summary_path.name}\")\n",
    "\n",
    "        df_summary = pd.DataFrame(portfolio_metrics)\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(f\"FINAL PORTFOLIO METRICS (v{FRAMEWORK_VERSION})\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        display_cols = ['Asset', 'Sharpe', 'OOS_AUC', 'SharpeSig', 'Return', 'MaxDD']\n",
    "        print(df_summary[display_cols].to_string(index=False))\n",
    "\n",
    "        print(f\"\\nAverage Sharpe:        {df_summary['Sharpe'].mean():.4f}\")\n",
    "        print(f\"Average OOS AUC:       {df_summary['OOS_AUC'].mean():.4f}\")\n",
    "        print(f\"Significant (Î±=0.05):  {df_summary['SharpeSig'].sum()} / {len(df_summary)}\")\n",
    "\n",
    "        csv_path = config.report_dir / f\"portfolio_metrics_v{FRAMEWORK_VERSION.replace('.', '_')}.csv\"\n",
    "        df_summary.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… {FRAMEWORK_NAME} COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nðŸ“ Reports: {config.report_dir}\")\n",
    "\n",
    "    logger.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
